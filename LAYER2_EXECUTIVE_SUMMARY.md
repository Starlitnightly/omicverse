# Layer 2: DataStateInspector - Executive Summary

**Purpose**: Runtime validation of prerequisite chains by inspecting AnnData object state

**Status**: Planning Complete - Ready for Review

---

## What Layer 2 Does

Layer 2 adds **runtime intelligence** to the prerequisite tracking system:

```python
# User tries to run clustering
inspector = DataStateInspector(adata, registry)
result = inspector.validate_prerequisites('leiden')

if not result.is_valid:
    # Clear error message
    print("Cannot run leiden: neighbors graph is missing")

    # Actionable fix
    print("Run: sc.pp.neighbors(adata, n_neighbors=15)")

    # Auto-executable
    exec(result.suggestions[0].code)
```

**Before Layer 2**: Functions fail with cryptic errors
**After Layer 2**: Clear validation with actionable guidance

---

## Core Components (5)

### 1. DataStateInspector üéØ
**Purpose**: Main orchestrator
**What it does**: Validates prerequisites before function execution
**Key method**: `validate_prerequisites(function_name) -> ValidationResult`

### 2. DataValidators ‚úÖ
**Purpose**: Check data structure requirements
**What it does**: Verifies obs, obsm, obsp, uns, layers exist
**Key method**: `check_obsm(['X_pca', 'X_umap']) -> CheckResult`

### 3. PrerequisiteChecker üîç
**Purpose**: Detect executed functions
**What it does**: Infers execution history from AnnData state
**Key method**: `check_function_executed('pca') -> ExecutionResult`

### 4. SuggestionEngine üí°
**Purpose**: Generate fix suggestions
**What it does**: Creates code snippets to resolve issues
**Key method**: `generate_fix_suggestions() -> List[Suggestion]`

### 5. LLMFormatter ü§ñ
**Purpose**: Format for Layer 3
**What it does**: Structures output for LLM consumption
**Key method**: `format_for_agent() -> dict`

---

## Detection Strategy (3 Levels)

### Level 1: Metadata Markers (High Confidence)
```python
# Functions leave explicit markers
adata.uns['preprocessing'] = {'log1p': True, 'scale': True}
```
**Confidence**: 0.9-1.0 | **Reliability**: High ‚úÖ

### Level 2: Output Signatures (Medium Confidence)
```python
# Match known outputs
if 'X_pca' in adata.obsm and 'pca' in adata.uns:
    confidence = 0.8  # PCA likely executed
```
**Confidence**: 0.6-0.9 | **Reliability**: Medium ‚ö†Ô∏è

### Level 3: Distribution Analysis (Low Confidence)
```python
# Analyze data properties (optional, future)
if max(adata.X) < 10:
    confidence = 0.3  # Maybe log-transformed
```
**Confidence**: 0.0-0.6 | **Reliability**: Low (Optional)

---

## Implementation Timeline

**Total Duration**: 5 weeks

| Week | Phase | Deliverable | Status |
|------|-------|-------------|--------|
| 1 | Core Infrastructure | Inspector + Validators | Planned |
| 2 | Detection System | PrerequisiteChecker | Planned |
| 3 | Suggestion Engine | Code generation | Planned |
| 4 | LLM Integration | Formatters | Planned |
| 5 | Testing & Docs | Production ready | Planned |

---

## Key Design Decisions

### ‚úÖ Conservative Detection
- **Decision**: Only mark prerequisites satisfied with clear evidence
- **Rationale**: False positives more dangerous than false negatives
- **Impact**: Users trust validation results

### ‚úÖ Structured Output
- **Decision**: Format all results for LLM consumption
- **Rationale**: Enable Layer 3 intelligent assistance
- **Impact**: Seamless LLM integration

### ‚úÖ Actionable Suggestions
- **Decision**: Generate executable code snippets
- **Rationale**: Users need immediate fixes, not explanations
- **Impact**: Faster problem resolution

### ‚úÖ Confidence Scores
- **Decision**: Report detection confidence (0.0-1.0)
- **Rationale**: Allow users to evaluate reliability
- **Impact**: Transparent, trustworthy system

---

## Example Usage

### Basic Validation
```python
import omicverse as ov

# Load data
adata = sc.datasets.pbmc3k()

# Validate
inspector = ov.utils.DataStateInspector(adata)
result = inspector.validate_prerequisites('leiden')

# Result
print(result.is_valid)  # False
print(result.missing_prerequisites)  # ['neighbors']
print(result.suggestions[0].code)  # 'sc.pp.neighbors(adata, n_neighbors=15)'
```

### Automated Fixing
```python
# Check and auto-fix
result = inspector.validate_prerequisites('leiden')
if not result.is_valid:
    for suggestion in result.suggestions:
        if suggestion.auto_executable:
            print(f"Executing: {suggestion.description}")
            exec(suggestion.code)

# Verify and proceed
result = inspector.validate_prerequisites('leiden')
if result.is_valid:
    sc.tl.leiden(adata)
```

### LLM Integration (Layer 3 Preview)
```python
# Format for LLM
result = inspector.validate_prerequisites('leiden')
llm_input = formatter.format_for_agent(result, user_intent="cluster cells")

# LLM receives:
{
  "function": "leiden",
  "validation_status": false,
  "missing_prerequisites": ["neighbors"],
  "suggested_fixes": [{
    "code": "sc.pp.neighbors(adata, n_neighbors=15)",
    "explanation": "Compute KNN graph",
    "auto_executable": true
  }],
  "llm_prompt": "User wants to cluster cells but neighbors graph is missing. Run: sc.pp.neighbors(adata)"
}
```

---

## Success Metrics

### Quantitative
- ‚úÖ **Detection Accuracy**: ‚â•90% for preprocessing functions
- ‚úÖ **False Positive Rate**: <5%
- ‚úÖ **Performance**: <100ms validation time
- ‚úÖ **Coverage**: All 36 Layer 1 functions

### Qualitative
- ‚úÖ **Clarity**: Error messages are actionable
- ‚úÖ **Integration**: Seamless with existing workflows
- ‚úÖ **Reliability**: Users trust validation results
- ‚úÖ **Extensibility**: Easy to add new detectors

---

## Risk Assessment

### Low Risk ‚úÖ
- Performance issues (mitigated by caching)
- API instability (thorough testing)

### Medium Risk ‚ö†Ô∏è
- Inaccurate detection (multiple strategies, confidence scores)
- False positives (conservative thresholds)
- Scope creep (clear phase boundaries)

### Mitigation
All risks have clear mitigation strategies in full plan

---

## Integration Points

### With Layer 1 (Registry) ‚úÖ
```python
# Access function metadata
meta = registry.get_function('leiden')
prerequisites = meta['prerequisites']
requires = meta['requires']
auto_fix = meta['auto_fix']
```

### With Layer 3 (LLM) üîÆ
```python
# Provide structured output
validation = inspector.validate_prerequisites('leiden')
llm_input = formatter.format_for_agent(validation)
# LLM can understand and act on validation results
```

### With OmicVerse Functions üîß
```python
# Optional validation hooks
@register_function(...)
def leiden(adata, **kwargs):
    if VALIDATION_ENABLED:
        validate_or_raise('leiden', adata)
    # ... function logic
```

---

## Files & Structure

```
omicverse/utils/inspector/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ inspector.py              # DataStateInspector
‚îú‚îÄ‚îÄ validators.py             # DataValidators
‚îú‚îÄ‚îÄ prerequisite_checker.py   # PrerequisiteChecker
‚îú‚îÄ‚îÄ suggestion_engine.py      # SuggestionEngine
‚îú‚îÄ‚îÄ formatters.py             # LLMFormatter
‚îú‚îÄ‚îÄ data_structures.py        # Result classes
‚îú‚îÄ‚îÄ config.py                 # Configuration
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_inspector.py
    ‚îú‚îÄ‚îÄ test_validators.py
    ‚îú‚îÄ‚îÄ test_prerequisite_checker.py
    ‚îú‚îÄ‚îÄ test_suggestion_engine.py
    ‚îî‚îÄ‚îÄ test_formatters.py

Documentation:
‚îú‚îÄ‚îÄ LAYER2_DATASTATEINSPECTOR_PLAN.md  (Complete spec)
‚îú‚îÄ‚îÄ LAYER2_EXECUTIVE_SUMMARY.md        (This file)
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ inspector_guide.md
    ‚îú‚îÄ‚îÄ api_reference.md
    ‚îî‚îÄ‚îÄ examples/
```

---

## Key Takeaways

### What Layer 2 Provides
1. ‚úÖ **Runtime Validation**: Check prerequisites before execution
2. ‚úÖ **Clear Errors**: Actionable messages, not cryptic failures
3. ‚úÖ **Auto-Fix**: Generate code to resolve issues
4. ‚úÖ **LLM-Ready**: Structured output for Layer 3
5. ‚úÖ **Reliable**: Conservative detection with confidence scores

### Why It Matters
- **Better UX**: Users understand what's wrong and how to fix it
- **Faster Development**: Automated prerequisite resolution
- **Fewer Errors**: Catch issues before they cause failures
- **LLM Integration**: Foundation for intelligent assistance
- **Production Quality**: Robust, tested, documented

### Next Steps
1. **Review this summary + full plan**
2. **Approve approach or suggest changes**
3. **Begin Phase 1 implementation**
4. **5-week timeline to production**

---

## Questions for Review

1. **Scope**: Is the 5-component architecture appropriate?
2. **Detection**: Are the 3 detection levels sufficient?
3. **Timeline**: Is 5 weeks realistic?
4. **Integration**: Any concerns about Layer 1/3 integration?
5. **Risks**: Any additional risks to consider?
6. **Features**: Any critical features missing?

---

## Approval Checklist

- [ ] Architecture approved
- [ ] Detection strategy approved
- [ ] Timeline acceptable
- [ ] Success metrics agreed
- [ ] Risk mitigation acceptable
- [ ] Ready to begin implementation

---

**Full Plan**: See `LAYER2_DATASTATEINSPECTOR_PLAN.md` (12,000+ words)

**Status**: Awaiting Review & Approval

**Next**: Begin Phase 1 implementation upon approval

**Contact**: Ready to answer questions and adjust plan as needed

---

**Version**: 1.0
**Date**: 2025-11-11
**Author**: Claude (Anthropic)
