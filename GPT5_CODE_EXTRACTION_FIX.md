# GPT-5 Code Extraction Fix - Complete Solution

**Issue**: GPT-5 fails with `Could not extract executable code: no code candidates found in the response`

**Root Causes Identified**:
1. GPT-5 uses Responses API with different response structure
2. GPT-5 may include reasoning text before code blocks
3. Code extraction patterns may not match GPT-5's output format
4. No diagnostic logging to see what GPT-5 actually returns
5. 0.00s execution time suggests possible API call failure

---

## Solution 1: Add Diagnostic Logging

### File: `omicverse/utils/agent_backend.py`

**Location**: In `_chat_via_openai_responses` method, after line 638

**Add logging before returning the response**:

```python
# After extracting the response text (around line 698), ADD:

# Diagnostic logging for GPT-5 responses
import logging
logger = logging.getLogger(__name__)

# Before the final return or raise, add diagnostic info
response_text = ""  # (will be set by extraction logic above)

# Log response structure for debugging
logger.debug(f"GPT-5 Response API: model={self.config.model}")
logger.debug(f"GPT-5 Response length: {len(response_text)} chars")
logger.debug(f"GPT-5 Response preview (first 500 chars): {response_text[:500]}")
logger.debug(f"GPT-5 Response type: {type(resp).__name__}")

# Also add try-except around the entire _make_responses_sdk_call with better error handling:
```

**Complete replacement for lines 611-713**:

```python
def _make_responses_sdk_call():
    """Make GPT-5 Responses API call with enhanced error handling and logging."""
    import logging
    logger = logging.getLogger(__name__)

    try:
        # Responses API uses 'instructions' for system prompt
        # and 'input' as a string (not message array)
        # Note: gpt-5 Responses API does not support temperature parameter
        input_payload = [
            {
                "role": "system",
                "content": [
                    {"type": "input_text", "text": self.config.system_prompt}
                ],
            },
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": user_prompt}
                ],
            },
        ]

        logger.debug(f"GPT-5 Responses API call: model={self.config.model}, input_length={len(user_prompt)}")

        # GPT-5 models use reasoning tokens - control effort for response quality
        # Set reasoning effort to 'high' for maximum reasoning capability and best quality responses
        resp = client.responses.create(
            model=self.config.model,
            input=input_payload,
            instructions=self.config.system_prompt,
            max_output_tokens=self.config.max_tokens,
            reasoning={"effort": "high"}  # Use high reasoning effort for better quality responses
        )

        logger.debug(f"GPT-5 API call succeeded, response type: {type(resp).__name__}")
        logger.debug(f"GPT-5 response attributes: {[attr for attr in dir(resp) if not attr.startswith('_')]}")

        # Capture usage information from Responses API (only if numeric)
        if hasattr(resp, 'usage') and resp.usage is not None:
            usage = resp.usage
            pt = _coerce_int(getattr(usage, 'input_tokens', None))
            if pt is None:
                pt = _coerce_int(getattr(usage, 'prompt_tokens', None))
            ct = _coerce_int(getattr(usage, 'output_tokens', None))
            if ct is None:
                ct = _coerce_int(getattr(usage, 'completion_tokens', None))
            tt = _coerce_int(getattr(usage, 'total_tokens', None))
            tt = _compute_total(pt, ct, tt)
            if tt is not None:
                self.last_usage = Usage(
                    input_tokens=pt or 0,
                    output_tokens=ct or 0,
                    total_tokens=tt,
                    model=self.config.model,
                    provider=self.config.provider
                )
                logger.debug(f"GPT-5 usage: input={pt}, output={ct}, total={tt}")

        # Extract text from Responses API format with fallback chain
        response_text = None

        # Try output_text first (most common)
        if hasattr(resp, 'output_text') and resp.output_text:
            response_text = resp.output_text
            logger.debug("GPT-5: Extracted from output_text")

        # Try output.text
        elif hasattr(resp, 'output'):
            output = resp.output
            # Direct string
            if isinstance(output, str):
                response_text = output
                logger.debug("GPT-5: Extracted from output (string)")
            # Object with .text
            elif hasattr(output, 'text') and getattr(output, 'text'):
                response_text = getattr(output, 'text')
                logger.debug("GPT-5: Extracted from output.text")
            # Object with .content (list of parts)
            elif hasattr(output, 'content'):
                parts = getattr(output, 'content')
                try:
                    for p in parts:
                        # p may be object or dict
                        if hasattr(p, 'text') and getattr(p, 'text'):
                            response_text = getattr(p, 'text')
                            logger.debug("GPT-5: Extracted from output.content[].text (object)")
                            break
                        if isinstance(p, dict) and p.get('text'):
                            response_text = p['text']
                            logger.debug("GPT-5: Extracted from output.content[].text (dict)")
                            break
                except Exception as e:
                    logger.warning(f"GPT-5: Error iterating output.content: {e}")
            # List (first element may be dict or object)
            elif isinstance(output, list) and len(output) > 0:
                first = output[0]
                if isinstance(first, str):
                    response_text = first
                    logger.debug("GPT-5: Extracted from output[0] (string)")
                elif hasattr(first, 'text') and getattr(first, 'text'):
                    response_text = getattr(first, 'text')
                    logger.debug("GPT-5: Extracted from output[0].text")
                elif isinstance(first, dict) and first.get('text'):
                    response_text = first['text']
                    logger.debug("GPT-5: Extracted from output[0]['text']")

        # Fallback: try text attribute directly
        if not response_text and hasattr(resp, 'text') and resp.text:
            response_text = resp.text
            logger.debug("GPT-5: Extracted from text attribute")

        # Final validation
        if response_text:
            logger.info(f"GPT-5 response extracted successfully: {len(response_text)} chars")
            logger.debug(f"GPT-5 response preview (first 500 chars):\n{response_text[:500]}")
            logger.debug(f"GPT-5 response preview (last 500 chars):\n{response_text[-500:]}")
            return response_text

        # If nothing worked, provide diagnostic info
        error_msg = (
            f"GPT-5 Responses API: Could not extract text from response.\n"
            f"Response type: {type(resp).__name__}\n"
            f"Available attributes: {[attr for attr in dir(resp) if not attr.startswith('_')]}\n"
            f"Has output: {hasattr(resp, 'output')}\n"
            f"Has output_text: {hasattr(resp, 'output_text')}\n"
            f"Has text: {hasattr(resp, 'text')}"
        )

        # Try to get any string representation for debugging
        try:
            resp_str = str(resp)
            error_msg += f"\nString representation (first 1000 chars): {resp_str[:1000]}"
        except Exception:
            pass

        logger.error(error_msg)
        raise RuntimeError(error_msg)

    except Exception as e:
        logger.error(f"GPT-5 Responses API call failed: {type(e).__name__}: {e}", exc_info=True)
        raise
```

---

## Solution 2: Enhanced Code Extraction

### File: `omicverse/utils/smart_agent.py`

**Location**: Replace `_gather_code_candidates` method (line 1234)

**Problem**: Current regex patterns may not match GPT-5's code formatting

**Solution**: Enhanced pattern matching with multiple strategies

```python
def _gather_code_candidates(self, response_text: str) -> List[str]:
    """Collect possible Python snippets from fenced or inline blocks.

    Enhanced to handle various code block formats including GPT-5 responses.
    """
    import logging
    logger = logging.getLogger(__name__)

    candidates = []

    # Strategy 1: Standard fenced code blocks with python marker
    fenced_python = re.compile(r"```python\s*(.*?)```", re.DOTALL | re.IGNORECASE)
    for match in fenced_python.finditer(response_text):
        code = textwrap.dedent(match.group(1)).strip()
        if code:
            candidates.append(code)
            logger.debug(f"Found code candidate (fenced python): {len(code)} chars")

    # Strategy 2: Generic fenced code blocks (```)
    fenced_generic = re.compile(r"```\s*(.*?)```", re.DOTALL)
    for match in fenced_generic.finditer(response_text):
        code = textwrap.dedent(match.group(1)).strip()
        # Skip if already captured by python-specific pattern
        if code and code not in candidates:
            # Heuristic: check if it looks like Python
            if self._looks_like_python(code):
                candidates.append(code)
                logger.debug(f"Found code candidate (fenced generic): {len(code)} chars")

    # Strategy 3: Code blocks with language identifiers (py, python3, etc.)
    fenced_variants = re.compile(r"```(?:py|python3|python)\s*(.*?)```", re.DOTALL | re.IGNORECASE)
    for match in fenced_variants.finditer(response_text):
        code = textwrap.dedent(match.group(1)).strip()
        if code and code not in candidates:
            candidates.append(code)
            logger.debug(f"Found code candidate (fenced variant): {len(code)} chars")

    # Strategy 4: Code after "Here's the code:" or similar markers
    code_intro_patterns = [
        r"(?:Here'?s? (?:the )?code:?|Code:?|Python code:?)\s*```(?:python)?\s*(.*?)```",
        r"(?:The (?:following )?code|Solution):?\s*```(?:python)?\s*(.*?)```",
    ]
    for pattern in code_intro_patterns:
        intro_match = re.search(pattern, response_text, re.DOTALL | re.IGNORECASE)
        if intro_match:
            code = textwrap.dedent(intro_match.group(1)).strip()
            if code and code not in candidates:
                candidates.append(code)
                logger.debug(f"Found code candidate (with intro): {len(code)} chars")

    # Strategy 5: GPT-5 specific - code might appear after reasoning text
    # Look for the LAST code block (most likely to be the final code)
    if not candidates:
        all_fenced = list(re.finditer(r"```(?:python)?\s*(.*?)```", response_text, re.DOTALL | re.IGNORECASE))
        if all_fenced:
            last_code = textwrap.dedent(all_fenced[-1].group(1)).strip()
            if last_code and self._looks_like_python(last_code):
                candidates.append(last_code)
                logger.debug(f"Found code candidate (last block): {len(last_code)} chars")

    if candidates:
        logger.info(f"Total code candidates found: {len(candidates)}")
        return candidates

    # Strategy 6: Inline extraction as fallback
    logger.debug("No fenced code blocks found, trying inline extraction")
    inline = self._extract_inline_python(response_text)
    if inline:
        logger.debug(f"Found inline code candidate: {len(inline)} chars")
        return [inline]

    logger.warning("No code candidates found in response")
    logger.debug(f"Response text (first 500 chars): {response_text[:500]}")
    logger.debug(f"Response text (last 500 chars): {response_text[-500:]}")
    return []

def _looks_like_python(self, code: str) -> bool:
    """Heuristic check if code snippet looks like Python."""
    # Check for Python-like patterns
    python_indicators = [
        r'\bimport\b',
        r'\bfrom\b.*\bimport\b',
        r'\bdef\b',
        r'\bclass\b',
        r'\bfor\b.*\bin\b',
        r'\bif\b.*:',
        r'\bwhile\b.*:',
        r'\btry\b.*:',
        r'\bexcept\b',
        r'\bwith\b.*:',
        r'\bprint\s*\(',
        r'\badata\b',
        r'\bov\.',
        r'\bsc\.',
    ]

    # Count how many indicators are present
    matches = sum(1 for pattern in python_indicators if re.search(pattern, code))

    # If at least 2 Python indicators, probably Python
    return matches >= 2
```

**Add the new helper method** (after `_gather_code_candidates`):

```python
def _looks_like_python(self, code: str) -> bool:
    """Heuristic check if code snippet looks like Python.

    Returns True if the code contains multiple Python-specific patterns.
    """
    # Check for Python-like patterns
    python_indicators = [
        r'\bimport\b',
        r'\bfrom\b.*\bimport\b',
        r'\bdef\b',
        r'\bclass\b',
        r'\bfor\b.*\bin\b',
        r'\bif\b.*:',
        r'\bwhile\b.*:',
        r'\btry\b.*:',
        r'\bexcept\b',
        r'\bwith\b.*:',
        r'\bprint\s*\(',
        r'\badata\b',
        r'\bov\.',
        r'\bsc\.',
        r'=\s*\[',  # List assignment
        r'=\s*\{',  # Dict assignment
    ]

    # Count how many indicators are present
    matches = sum(1 for pattern in python_indicators if re.search(pattern, code))

    # If at least 2 Python indicators, probably Python
    return matches >= 2
```

---

## Solution 3: Better Error Messages

### File: `omicverse/utils/smart_agent.py`

**Location**: Update `_extract_python_code` method (line 1211)

**Replace with enhanced version**:

```python
def _extract_python_code(self, response_text: str) -> str:
    """Extract executable Python code from the agent response using AST validation.

    Enhanced with better error messages showing what was found.
    """
    import logging
    logger = logging.getLogger(__name__)

    # Log response preview for debugging
    logger.debug(f"Extracting code from response ({len(response_text)} chars)")
    logger.debug(f"Response preview: {response_text[:200]}...")

    candidates = self._gather_code_candidates(response_text)

    if not candidates:
        # Provide helpful error with response preview
        error_msg = (
            f"No code candidates found in the response.\n"
            f"Response length: {len(response_text)} characters\n"
            f"Response preview (first 300 chars):\n{response_text[:300]}\n"
            f"Response preview (last 300 chars):\n{response_text[-300:]}\n"
            f"Expected code blocks like:\n"
            f"  ```python\n"
            f"  import omicverse as ov\n"
            f"  ...\n"
            f"  ```"
        )
        logger.error(error_msg)
        raise ValueError(error_msg)

    logger.info(f"Found {len(candidates)} code candidate(s)")

    syntax_errors = []
    for i, candidate in enumerate(candidates):
        logger.debug(f"Validating candidate {i+1}/{len(candidates)}: {len(candidate)} chars")
        logger.debug(f"Candidate preview: {candidate[:100]}...")

        try:
            normalized = self._normalize_code_candidate(candidate)
        except ValueError as exc:
            error_detail = f"Candidate {i+1} normalization failed: {exc}"
            logger.debug(error_detail)
            syntax_errors.append(error_detail)
            continue

        try:
            ast.parse(normalized)
            logger.info(f"Candidate {i+1} validated successfully!")
            return normalized
        except SyntaxError as exc:
            error_detail = (
                f"Candidate {i+1} syntax error at line {exc.lineno}: {exc.msg}\n"
                f"  {exc.text if exc.text else '(no text)'}"
            )
            logger.debug(error_detail)
            syntax_errors.append(error_detail)
            continue

    # All candidates failed - provide detailed error
    error_msg = (
        f"No syntactically valid Python code found.\n"
        f"Tried {len(candidates)} candidate(s):\n" +
        "\n".join(f"  {i+1}. {err}" for i, err in enumerate(syntax_errors))
    )
    logger.error(error_msg)
    raise ValueError(error_msg)
```

---

## Solution 4: Enable Debug Logging

### File: Create new file `omicverse/utils/logging_config.py`

```python
"""Logging configuration for OmicVerse agent debugging."""

import logging
import os


def enable_agent_debug_logging():
    """Enable debug logging for agent components.

    Set environment variable OVAGENT_DEBUG=1 to enable.
    """
    if os.getenv('OVAGENT_DEBUG', '').lower() in ('1', 'true', 'yes'):
        # Configure root logger
        logging.basicConfig(
            level=logging.DEBUG,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            force=True
        )

        # Set specific loggers
        logging.getLogger('omicverse.utils.smart_agent').setLevel(logging.DEBUG)
        logging.getLogger('omicverse.utils.agent_backend').setLevel(logging.DEBUG)

        print("ðŸ” OVAgent debug logging enabled")


# Auto-enable if environment variable is set
enable_agent_debug_logging()
```

### File: `omicverse/utils/smart_agent.py`

**Location**: Add at top of file, after imports

```python
# Enable debug logging if requested
from .logging_config import enable_agent_debug_logging
enable_agent_debug_logging()
```

---

## Solution 5: GPT-5 Model Validation

### File: `omicverse/utils/agent_backend.py`

**Location**: In `__init__` method, add validation

**After line with `self.config = ModelConfig.from_model_id(...)`**, add:

```python
# Validate GPT-5 model access
if 'gpt-5' in self.config.model.lower():
    try:
        # Quick validation that OpenAI SDK is available
        from openai import OpenAI

        # Check API key is set
        api_key = self._resolve_api_key()
        if not api_key:
            warnings.warn(
                f"GPT-5 model '{self.config.model}' requires OPENAI_API_KEY to be set. "
                "Agent initialization will succeed but API calls will fail."
            )
        else:
            # Optionally: could add a test call here
            pass
    except ImportError:
        warnings.warn(
            f"GPT-5 model '{self.config.model}' requires 'openai' package. "
            "Install with: pip install openai"
        )
```

---

## How to Apply These Fixes

### Quick Test (Immediate):

1. **Enable debug logging**:
   ```bash
   export OVAGENT_DEBUG=1
   python test_ovagent_openai_gemini.py
   ```

   This will show you what GPT-5 is actually returning.

### Full Fix (Recommended):

1. **Apply Solution 1**: Enhanced logging in `agent_backend.py`
   - Replace the `_make_responses_sdk_call` function with the enhanced version

2. **Apply Solution 2**: Enhanced code extraction in `smart_agent.py`
   - Replace `_gather_code_candidates` method
   - Add `_looks_like_python` helper method

3. **Apply Solution 3**: Better error messages in `smart_agent.py`
   - Replace `_extract_python_code` method

4. **Apply Solution 4**: Add logging configuration
   - Create `logging_config.py`
   - Import it in `smart_agent.py`

5. **Apply Solution 5**: Add GPT-5 validation in `agent_backend.py`
   - Add validation in `__init__`

---

## Testing the Fix

### Test 1: Enable Logging
```bash
export OVAGENT_DEBUG=1
python3 test_ovagent_openai_gemini.py 2>&1 | grep -A 10 "GPT-5"
```

This will show:
- What GPT-5 returns
- Why code extraction fails
- Exactly what patterns were tried

### Test 2: Test Single GPT-5 Request
```python
import omicverse as ov
import scanpy as sc
import os

os.environ['OVAGENT_DEBUG'] = '1'

agent = ov.Agent(model='gpt-5', api_key=os.getenv('OPENAI_API_KEY'))
adata = sc.datasets.pbmc3k()

try:
    result = agent.run('quality control with nUMI>500, mito<0.2', adata)
    print(f"âœ… Success! {result.n_obs} cells")
except Exception as e:
    print(f"âŒ Error: {e}")
    # Check logs for diagnostic info
```

### Test 3: Verify Code Extraction
```python
# Test the enhanced code extraction directly
from omicverse.utils.smart_agent import OmicVerseAgent

agent = OmicVerseAgent(model='gpt-5', api_key='test')

# Test various response formats
test_responses = [
    "```python\nimport omicverse as ov\nadata = ov.pp.qc(adata)\n```",
    "Here's the code:\n```\nimport omicverse as ov\nadata = ov.pp.qc(adata)\n```",
    "Let me think... The solution is:\n```python\nimport omicverse as ov\nadata = ov.pp.qc(adata)\n```",
]

for resp in test_responses:
    try:
        code = agent._extract_python_code(resp)
        print(f"âœ… Extracted: {code[:50]}...")
    except Exception as e:
        print(f"âŒ Failed: {e}")
```

---

## Expected Results After Fix

### Before Fix:
```
âŒ ERROR - Priority 2 failed
Error: Could not extract executable code: no code candidates found in the response
```

### After Fix:
```
âœ… SUCCESS - Priority 1/2 completed successfully!
   QC completed in XX.XXs
   Cells: 2700 â†’ 2648 (98.1% retained)
âœ… PASSED - 2648 cells retained
```

---

## Summary

These fixes address:
1. âœ… **Diagnostic logging** - See what GPT-5 returns
2. âœ… **Enhanced code extraction** - Handle more response formats
3. âœ… **GPT-5 specific patterns** - Reasoning text before code
4. âœ… **Better error messages** - Show what was found vs expected
5. âœ… **Validation** - Check GPT-5 is accessible

The root cause is likely GPT-5 returning code in a format that doesn't match the current regex patterns, possibly including reasoning text or using different code block delimiters. These fixes make the extraction much more robust.
