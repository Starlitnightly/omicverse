{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Intelligent Prerequisite Detection with PBMC3k Data\n",
    "\n",
    "This notebook demonstrates the **hybrid prerequisite detection system** using real PBMC3k single-cell data.\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "The system uses **two layers** to intelligently handle function prerequisites:\n",
    "\n",
    "- **Layer 1: Runtime Data Inspection** - Examines actual data state (no hardcoding)\n",
    "- **Layer 2: LLM Inference** - Analyzes function documentation and reasons about prerequisites\n",
    "\n",
    "## What You'll See\n",
    "\n",
    "1. **Data State Inspection** - How the system examines your data\n",
    "2. **Smart Classification** - How it decides simple vs. complex tasks\n",
    "3. **Auto-Fix Prerequisites** - Automatically running simple prerequisites\n",
    "4. **Workflow Escalation** - Detecting when full pipeline is needed\n",
    "5. **Real Agent Usage** - Using ov.Agent with intelligent prerequisite handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omicverse as ov\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "ov.plot_set()\n",
    "\n",
    "print(f\"OmicVerse version: {ov.__version__}\")\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PBMC3k Data\n",
    "\n",
    "We'll use the standard PBMC3k dataset from scanpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PBMC3k data\n",
    "adata = sc.datasets.pbmc3k()\n",
    "\n",
    "print(f\"üìä Loaded PBMC3k data: {adata.shape[0]} cells √ó {adata.shape[1]} genes\")\n",
    "print(f\"Data type: {type(adata)}\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Layer 1 - Runtime Data Inspection\n",
    "\n",
    "Let's see how **Layer 1** examines the current data state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omicverse.utils.smart_agent import DataStateInspector\n",
    "\n",
    "# Inspect raw data state\n",
    "print(\"üîç Layer 1: Inspecting RAW DATA state...\\n\")\n",
    "\n",
    "state_raw = DataStateInspector.inspect(adata)\n",
    "\n",
    "print(\"üìã Data State Report:\")\n",
    "print(f\"  Shape: {state_raw['shape'][0]:,} cells √ó {state_raw['shape'][1]:,} genes\")\n",
    "print(f\"  Available layers: {state_raw['available']['layers']}\")\n",
    "print(f\"  Available obsm: {state_raw['available']['obsm']}\")\n",
    "print(f\"  Available uns: {state_raw['available']['uns'][:5]}...\")\n",
    "print(f\"  Detected capabilities: {state_raw['capabilities']}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "if not state_raw['capabilities']:\n",
    "    print(\"  ‚ö†Ô∏è  This is RAW data with no preprocessing\")\n",
    "    print(\"  ‚ö†Ô∏è  Functions requiring preprocessing will need full pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-Readable Summary\n",
    "\n",
    "Layer 1 can generate a human-readable summary for LLM prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = DataStateInspector.get_readable_summary(adata)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Compatibility Check\n",
    "\n",
    "Layer 1 can check if a function is compatible with current data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if PCA can run on raw data\n",
    "print(\"üîç Checking PCA compatibility on raw data...\\n\")\n",
    "\n",
    "compat = DataStateInspector.check_compatibility(\n",
    "    adata,\n",
    "    function_name='pca',\n",
    "    function_signature=\"(adata, layer='scaled', n_pcs=50)\",\n",
    "    function_category='preprocessing'\n",
    ")\n",
    "\n",
    "print(f\"Likely compatible: {compat['likely_compatible']}\")\n",
    "print(f\"\\nWarnings:\")\n",
    "for warning in compat['warnings']:\n",
    "    print(f\"  ‚ö†Ô∏è  {warning}\")\n",
    "\n",
    "print(f\"\\nSuggestions:\")\n",
    "for suggestion in compat['suggestions']:\n",
    "    print(f\"  üí° {suggestion}\")\n",
    "\n",
    "print(f\"\\nReasoning: {compat['reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Data State-Aware Classification\n",
    "\n",
    "The system uses data state to classify tasks as **SIMPLE** or **COMPLEX**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "# Check if API key is available\n",
    "has_api_key = bool(os.getenv('OPENAI_API_KEY') or os.getenv('ANTHROPIC_API_KEY'))\n",
    "\n",
    "if not has_api_key:\n",
    "    print(\"‚ö†Ô∏è  No API key found. Skipping agent examples.\")\n",
    "    print(\"   Set OPENAI_API_KEY or ANTHROPIC_API_KEY to test agent functionality.\\n\")\n",
    "else:\n",
    "    from omicverse.utils.smart_agent import OmicVerseAgent\n",
    "    \n",
    "    # Initialize agent\n",
    "    agent = OmicVerseAgent(model='gpt-4o-mini')\n",
    "    \n",
    "    print(\"\\nü§ñ Testing Task Classification with Data State Awareness...\\n\")\n",
    "    \n",
    "    # Test 1: PCA on raw data (should be COMPLEX)\n",
    "    async def test_classification():\n",
    "        print(\"Test 1: PCA on RAW DATA\")\n",
    "        complexity = await agent._analyze_task_complexity(\"Run PCA\", adata)\n",
    "        print(f\"  Request: 'Run PCA'\")\n",
    "        print(f\"  Data state: Raw (no preprocessing)\")\n",
    "        print(f\"  Classification: {complexity.upper()}\")\n",
    "        print(f\"  Reason: PCA needs preprocessing, but data is raw\\n\")\n",
    "        \n",
    "        return complexity\n",
    "    \n",
    "    # Run async test\n",
    "    complexity_result = await test_classification()\n",
    "    \n",
    "    if complexity_result == 'complex':\n",
    "        print(\"‚úÖ CORRECT: System detected this needs full preprocessing pipeline\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Unexpected classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Preprocessing the Data\n",
    "\n",
    "Let's preprocess the data step by step and observe how the system's assessment changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Running Quality Control...\\n\")\n",
    "\n",
    "# QC with standard thresholds\n",
    "adata_qc = adata.copy()\n",
    "adata_qc = ov.pp.qc(\n",
    "    adata_qc,\n",
    "    tresh={'mito_perc': 0.2, 'nUMIs': 500, 'detected_genes': 250}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ QC complete: {adata_qc.shape[0]} cells remaining\")\n",
    "\n",
    "# Check data state after QC\n",
    "state_qc = DataStateInspector.inspect(adata_qc)\n",
    "print(f\"\\nüìã Data State After QC:\")\n",
    "print(f\"  Capabilities: {state_qc['capabilities']}\")\n",
    "print(f\"  Layers: {state_qc['available']['layers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing (Normalization + Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Running Preprocessing (normalization + HVG + scaling)...\\n\")\n",
    "\n",
    "# Store raw counts\n",
    "adata_qc.layers['counts'] = adata_qc.X.copy()\n",
    "\n",
    "# Preprocess\n",
    "adata_preprocessed = adata_qc.copy()\n",
    "adata_preprocessed = ov.pp.preprocess(\n",
    "    adata_preprocessed,\n",
    "    mode='shiftlog|pearson',\n",
    "    n_HVGs=2000,\n",
    "    target_sum=1e4\n",
    ")\n",
    "\n",
    "# Scale\n",
    "adata_preprocessed = ov.pp.scale(adata_preprocessed)\n",
    "\n",
    "print(f\"‚úÖ Preprocessing complete\")\n",
    "\n",
    "# Check data state after preprocessing\n",
    "state_preprocessed = DataStateInspector.inspect(adata_preprocessed)\n",
    "print(f\"\\nüìã Data State After Preprocessing:\")\n",
    "print(f\"  Capabilities: {state_preprocessed['capabilities']}\")\n",
    "print(f\"  Layers: {state_preprocessed['available']['layers']}\")\n",
    "\n",
    "print(\"\\nüí° Now the data is ready for PCA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-check PCA Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Re-checking PCA compatibility on PREPROCESSED data...\\n\")\n",
    "\n",
    "compat_preprocessed = DataStateInspector.check_compatibility(\n",
    "    adata_preprocessed,\n",
    "    function_name='pca',\n",
    "    function_signature=\"(adata, layer='scaled', n_pcs=50)\",\n",
    "    function_category='preprocessing'\n",
    ")\n",
    "\n",
    "print(f\"Likely compatible: {compat_preprocessed['likely_compatible']}\")\n",
    "print(f\"Warnings: {len(compat_preprocessed['warnings'])} (was {len(compat['warnings'])} before)\")\n",
    "print(f\"\\nReasoning: {compat_preprocessed['reasoning']}\")\n",
    "\n",
    "if len(compat_preprocessed['warnings']) == 0:\n",
    "    print(\"\\n‚úÖ SUCCESS: Data is now ready for PCA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification on Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_api_key:\n",
    "    print(\"ü§ñ Testing Classification on PREPROCESSED DATA...\\n\")\n",
    "    \n",
    "    async def test_preprocessed_classification():\n",
    "        complexity = await agent._analyze_task_complexity(\"Run PCA\", adata_preprocessed)\n",
    "        print(f\"  Request: 'Run PCA'\")\n",
    "        print(f\"  Data state: Preprocessed (has 'scaled' layer)\")\n",
    "        print(f\"  Classification: {complexity.upper()}\")\n",
    "        print(f\"  Reason: Data is ready, can execute directly\\n\")\n",
    "        return complexity\n",
    "    \n",
    "    complexity_preprocessed = await test_preprocessed_classification()\n",
    "    \n",
    "    if complexity_preprocessed == 'simple':\n",
    "        print(\"‚úÖ CORRECT: System detected data is ready for direct execution\")\n",
    "        print(\"\\nüí° Compare:\")\n",
    "        print(f\"  - Raw data ‚Üí COMPLEX (needs full pipeline)\")\n",
    "        print(f\"  - Preprocessed data ‚Üí SIMPLE (ready to execute)\")\n",
    "        print(\"\\nüéâ Data state awareness working perfectly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Layer 2 - LLM-Based Prerequisite Inference\n",
    "\n",
    "Now let's see **Layer 2** in action - LLM reasoning about prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_api_key:\n",
    "    from omicverse.utils.smart_agent import LLMPrerequisiteInference\n",
    "    from omicverse.utils.registry import _global_registry\n",
    "    \n",
    "    print(\"üß† Layer 2: LLM-Based Prerequisite Inference\\n\")\n",
    "    \n",
    "    # Get PCA function info from registry\n",
    "    pca_results = _global_registry.find('pca')\n",
    "    if pca_results:\n",
    "        pca_info = pca_results[0]\n",
    "        \n",
    "        # Test on raw data\n",
    "        print(\"Test 1: PCA on RAW DATA\\n\")\n",
    "        \n",
    "        async def test_llm_inference_raw():\n",
    "            inference_engine = agent._prerequisite_inference\n",
    "            \n",
    "            result = await inference_engine.infer_prerequisites(\n",
    "                function_name='pca',\n",
    "                function_info=pca_info,\n",
    "                data_state=state_raw,\n",
    "                skill_context=None\n",
    "            )\n",
    "            \n",
    "            print(f\"  Can run: {result['can_run']}\")\n",
    "            print(f\"  Confidence: {result['confidence']:.0%}\")\n",
    "            print(f\"  Complexity: {result['complexity'].upper()}\")\n",
    "            print(f\"  Missing items: {', '.join(result['missing_items'])}\")\n",
    "            print(f\"  Required steps: {' ‚Üí '.join(result['required_steps'])}\")\n",
    "            print(f\"  Auto-fixable: {result['auto_fixable']}\")\n",
    "            print(f\"\\n  LLM Reasoning: {result['reasoning']}\\n\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        result_raw = await test_llm_inference_raw()\n",
    "        \n",
    "        # Test on preprocessed data\n",
    "        print(\"\\nTest 2: PCA on PREPROCESSED DATA\\n\")\n",
    "        \n",
    "        async def test_llm_inference_preprocessed():\n",
    "            inference_engine = agent._prerequisite_inference\n",
    "            \n",
    "            result = await inference_engine.infer_prerequisites(\n",
    "                function_name='pca',\n",
    "                function_info=pca_info,\n",
    "                data_state=state_preprocessed,\n",
    "                skill_context=None\n",
    "            )\n",
    "            \n",
    "            print(f\"  Can run: {result['can_run']}\")\n",
    "            print(f\"  Confidence: {result['confidence']:.0%}\")\n",
    "            print(f\"  Complexity: {result['complexity'].upper()}\")\n",
    "            print(f\"  Missing items: {', '.join(result['missing_items']) if result['missing_items'] else 'None'}\")\n",
    "            print(f\"\\n  LLM Reasoning: {result['reasoning']}\\n\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        result_preprocessed = await test_llm_inference_preprocessed()\n",
    "        \n",
    "        print(\"\\n‚úÖ Layer 2 demonstrates intelligent reasoning:\")\n",
    "        print(f\"  - Analyzes function documentation\")\n",
    "        print(f\"  - Compares with current data state\")\n",
    "        print(f\"  - Provides structured recommendations\")\n",
    "        print(f\"  - No hardcoding - learns from documentation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Complete Analysis Pipeline\n",
    "\n",
    "Let's run a complete analysis to demonstrate the system in a realistic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA (Now that data is preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Running PCA on preprocessed data...\\n\")\n",
    "\n",
    "adata_pca = adata_preprocessed.copy()\n",
    "adata_pca = ov.pp.pca(adata_pca, layer='scaled', n_pcs=50)\n",
    "\n",
    "print(f\"‚úÖ PCA complete: {adata_pca.obsm['X_pca'].shape}\")\n",
    "\n",
    "# Check new state\n",
    "state_pca = DataStateInspector.inspect(adata_pca)\n",
    "print(f\"\\nüìã Data State After PCA:\")\n",
    "print(f\"  Capabilities: {state_pca['capabilities']}\")\n",
    "print(f\"  Available obsm: {state_pca['available']['obsm']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Leiden Clustering (Missing Neighbors)\n",
    "\n",
    "This demonstrates **auto-fixing** - clustering needs neighbors, but the system should detect it can auto-run neighbors since we have PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_api_key:\n",
    "    print(\"üß™ Testing: Leiden Clustering (data has PCA, missing neighbors)\\n\")\n",
    "    \n",
    "    # Get leiden function info\n",
    "    leiden_results = _global_registry.find('leiden')\n",
    "    if leiden_results:\n",
    "        leiden_info = leiden_results[0]\n",
    "        \n",
    "        async def test_leiden_inference():\n",
    "            inference_engine = agent._prerequisite_inference\n",
    "            \n",
    "            result = await inference_engine.infer_prerequisites(\n",
    "                function_name='leiden',\n",
    "                function_info=leiden_info,\n",
    "                data_state=state_pca,\n",
    "                skill_context=None\n",
    "            )\n",
    "            \n",
    "            print(f\"  Can run: {result['can_run']}\")\n",
    "            print(f\"  Confidence: {result['confidence']:.0%}\")\n",
    "            print(f\"  Complexity: {result['complexity'].upper()}\")\n",
    "            print(f\"  Missing items: {', '.join(result['missing_items'])}\")\n",
    "            print(f\"  Required steps: {' ‚Üí '.join(result['required_steps'])}\")\n",
    "            print(f\"  Auto-fixable: {result['auto_fixable']}\")\n",
    "            print(f\"\\n  LLM Reasoning: {result['reasoning']}\\n\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        leiden_result = await test_leiden_inference()\n",
    "        \n",
    "        if leiden_result['auto_fixable']:\n",
    "            print(\"\\n‚úÖ EXCELLENT: Layer 2 detected this is AUTO-FIXABLE\")\n",
    "            print(\"   The agent can automatically run neighbors before leiden\")\n",
    "            print(\"   This is a 1-step fix, no need for full workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually Run the Auto-Fix\n",
    "\n",
    "Let's manually demonstrate what the agent would do automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Demonstrating Auto-Fix: Neighbors + Leiden\\n\")\n",
    "\n",
    "adata_clustered = adata_pca.copy()\n",
    "\n",
    "# Auto-fix: Run neighbors first\n",
    "print(\"  Step 1: Auto-running neighbors (prerequisite)...\")\n",
    "adata_clustered = ov.pp.neighbors(\n",
    "    adata_clustered,\n",
    "    n_neighbors=15,\n",
    "    use_rep='X_pca'\n",
    ")\n",
    "print(\"  ‚úÖ Neighbors computed\")\n",
    "\n",
    "# Now run leiden\n",
    "print(\"  Step 2: Running leiden clustering...\")\n",
    "adata_clustered = ov.pp.leiden(adata_clustered, resolution=1.0)\n",
    "print(f\"  ‚úÖ Leiden complete: {adata_clustered.obs['leiden'].nunique()} clusters\")\n",
    "\n",
    "# Check final state\n",
    "state_final = DataStateInspector.inspect(adata_clustered)\n",
    "print(f\"\\nüìã Final Data State:\")\n",
    "print(f\"  Capabilities: {state_final['capabilities']}\")\n",
    "print(f\"  Available uns: neighbors = {'neighbors' in state_final['available']['uns']}\")\n",
    "print(f\"  Clustering columns: {state_final.get('clustering_columns', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute UMAP for visualization\n",
    "print(\"üé® Computing UMAP for visualization...\\n\")\n",
    "adata_viz = adata_clustered.copy()\n",
    "adata_viz = ov.pp.umap(adata_viz)\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot by leiden clusters\n",
    "sc.pl.umap(adata_viz, color='leiden', ax=axes[0], show=False, title='Leiden Clusters')\n",
    "\n",
    "# Plot by total counts\n",
    "sc.pl.umap(adata_viz, color='n_genes', ax=axes[1], show=False, title='Number of Genes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis complete!\")\n",
    "print(f\"   {adata_viz.shape[0]} cells\")\n",
    "print(f\"   {adata_viz.obs['leiden'].nunique()} clusters\")\n",
    "print(f\"   Ready for downstream analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Using the Agent (Optional)\n",
    "\n",
    "If you have an API key configured, you can use the actual agent with intelligent prerequisite handling.\n",
    "\n",
    "**Note**: This section requires `OPENAI_API_KEY` or `ANTHROPIC_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_api_key:\n",
    "    print(\"ü§ñ Using OmicVerse Agent with Intelligent Prerequisite Handling\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Example 1: Agent on preprocessed data (should work directly)\n",
    "    print(\"\\nExample 1: PCA on preprocessed data\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    async def agent_example_1():\n",
    "        adata_test = adata_preprocessed.copy()\n",
    "        result = await agent.run(\"Run PCA with 30 components\", adata_test)\n",
    "        print(f\"\\n‚úÖ Agent successfully executed PCA\")\n",
    "        print(f\"   Result shape: {result.obsm['X_pca'].shape if 'X_pca' in result.obsm else 'N/A'}\")\n",
    "        return result\n",
    "    \n",
    "    result1 = await agent_example_1()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nüí° What happened:\")\n",
    "    print(\"   1. Agent checked data state (Layer 1)\")\n",
    "    print(\"   2. Found 'scaled' layer available\")\n",
    "    print(\"   3. Classified as SIMPLE task\")\n",
    "    print(\"   4. Executed PCA directly\")\n",
    "    print(\"   5. No workflow escalation needed!\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping agent examples (no API key configured)\")\n",
    "    print(\"\\nTo use the agent:\")\n",
    "    print(\"  1. Set OPENAI_API_KEY or ANTHROPIC_API_KEY\")\n",
    "    print(\"  2. Re-run this cell\")\n",
    "    print(\"\\nThe agent will use the hybrid prerequisite detection system\")\n",
    "    print(\"to intelligently handle function prerequisites automatically.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What We Demonstrated\n",
    "\n",
    "### ‚úÖ Layer 1: Runtime Data Inspection\n",
    "- **Examines actual data state** (layers, obsm, uns, capabilities)\n",
    "- **No hardcoding** - just reports facts\n",
    "- **Compatibility checking** - warns about missing prerequisites\n",
    "- **Human-readable summaries** for LLM context\n",
    "\n",
    "### ‚úÖ Layer 2: LLM-Based Prerequisite Inference\n",
    "- **Analyzes function documentation** intelligently\n",
    "- **Compares needs vs. current state**\n",
    "- **Provides structured recommendations** (auto-fix vs. workflow)\n",
    "- **Learns from documentation** - no hardcoding!\n",
    "- **Caches results** for performance\n",
    "\n",
    "### ‚úÖ Data State-Aware Classification\n",
    "- **PCA on raw data** ‚Üí COMPLEX (needs full pipeline)\n",
    "- **PCA on preprocessed data** ‚Üí SIMPLE (ready to execute)\n",
    "- **Clustering with PCA** ‚Üí SIMPLE (can auto-run neighbors)\n",
    "- **Clustering without PCA** ‚Üí COMPLEX (needs preprocessing)\n",
    "\n",
    "### ‚úÖ Intelligent Auto-Fixing\n",
    "- **1-step prerequisites** ‚Üí Auto-run (e.g., neighbors before leiden)\n",
    "- **Multi-step prerequisites** ‚Üí Escalate to workflow\n",
    "- **Defensive validation** ‚Üí Checks before execution\n",
    "\n",
    "## Key Benefits\n",
    "\n",
    "| Feature | Old System | New Hybrid System |\n",
    "|---------|-----------|-------------------|\n",
    "| **Prerequisite checking** | ‚ùå None | ‚úÖ Automatic (2 layers) |\n",
    "| **Hardcoding** | ‚ùå Would need 100+ rules | ‚úÖ Zero hardcoding |\n",
    "| **Maintenance** | ‚ùå Manual updates | ‚úÖ Self-maintaining |\n",
    "| **Custom workflows** | ‚ùå Not supported | ‚úÖ Fully supported |\n",
    "| **Novel functions** | ‚ùå Needs new rules | ‚úÖ Learns automatically |\n",
    "| **Intelligence** | ‚ùå Pattern matching | ‚úÖ LLM reasoning |\n",
    "\n",
    "## Architecture Recap\n",
    "\n",
    "```\n",
    "Layer 1 (Runtime) ‚Üí Layer 2 (LLM) ‚Üí Classification ‚Üí Smart Execution\n",
    "     ‚Üì                   ‚Üì               ‚Üì                ‚Üì\n",
    "  Facts about       Intelligent      SIMPLE vs.     Auto-fix or\n",
    "  data state        reasoning        COMPLEX        Escalate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The **hybrid prerequisite detection system** provides:\n",
    "\n",
    "1. üéØ **Accuracy** - Never executes functions on unprepared data\n",
    "2. ü§ñ **Intelligence** - Learns from documentation, not hardcoded rules\n",
    "3. üöÄ **Performance** - Caching and smart classification\n",
    "4. üîÆ **Future-proof** - Adapts to any workflow automatically\n",
    "5. ‚ú® **User-friendly** - Auto-fixes simple issues transparently\n",
    "\n",
    "**No hardcoding. No maintenance. Just intelligence.**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
