# scGPT å®Œæ•´ä½¿ç”¨æŒ‡å—

åŸºäº omicverse/external/scllm æ¨¡å—çš„ç»Ÿä¸€ scGPT æ¥å£ä½¿ç”¨æŒ‡å—ã€‚

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—æ¶µç›–äº†ä½¿ç”¨ omicverse.external.scllm æ¨¡å—è¿›è¡Œ scGPT ç›¸å…³æ“ä½œçš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š

- **åŸºæœ¬ä½¿ç”¨**: ç»†èƒåµŒå…¥ã€ç»†èƒç±»å‹æ³¨é‡Š
- **æ¨¡å‹å¾®è°ƒ**: åœ¨å‚è€ƒæ•°æ®ä¸Šè®­ç»ƒåˆ†ç±»å™¨
- **æ‰¹æ¬¡ç§¯åˆ†**: å»é™¤æ‰¹æ¬¡æ•ˆåº”çš„å®Œæ•´å·¥ä½œæµ
- **ç«¯åˆ°ç«¯å·¥ä½œæµ**: è‡ªåŠ¨åŒ–çš„å®Œæ•´æµç¨‹

## ğŸ—ï¸ æ¶æ„ç®€ä»‹

### æ¨¡å—ç»“æ„
```
omicverse/external/scllm/
â”œâ”€â”€ __init__.py         # ç»Ÿä¸€å¯¼å…¥æ¥å£
â”œâ”€â”€ base.py            # åŸºç¡€æŠ½è±¡ç±»å’Œé…ç½®
â”œâ”€â”€ scgpt_model.py     # scGPT æ¨¡å‹å®ç°
â”œâ”€â”€ model_factory.py   # æ¨¡å‹å·¥å‚å’Œç®¡ç†å™¨
â””â”€â”€ scgpt/            # scGPT æ ¸å¿ƒç»„ä»¶
    â”œâ”€â”€ model/        # Transformer æ¨¡å‹
    â”œâ”€â”€ tokenizer/    # åŸºå› è¯æ±‡è¡¨å’Œåˆ†è¯å™¨
    â”œâ”€â”€ preprocess/   # æ•°æ®é¢„å¤„ç†
    â””â”€â”€ utils/        # å·¥å…·å‡½æ•°
```

### æ ¸å¿ƒç±»
- **SCLLMManager**: é«˜çº§ç®¡ç†æ¥å£ï¼Œæä¾›æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
- **ScGPTModel**: scGPT æ¨¡å‹çš„å…·ä½“å®ç°
- **ModelFactory**: æ¨¡å‹å·¥å‚ï¼Œæ”¯æŒåˆ›å»ºä¸åŒç±»å‹çš„æ¨¡å‹
- **ModelConfig**: æ¨¡å‹é…ç½®ç®¡ç†
- **TaskConfig**: ä»»åŠ¡ç‰¹å®šçš„é…ç½®ï¼ˆannotation, integration, generationï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬å®‰è£…è¦æ±‚

```python
# å¿…éœ€çš„åŸºç¡€ä¾èµ–
import omicverse as ov
import scanpy as sc
import pandas as pd
import numpy as np
```

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹æ³•

```python
# 1. åŠ è½½æ•°æ®
adata = sc.read_h5ad("your_data.h5ad")

# 2. åˆ›å»º scGPT ç®¡ç†å™¨
manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="/path/to/scgpt/model"  # åŒ…å« vocab.json, best_model.pt, args.json
)

# 3. è·å–ç»†èƒåµŒå…¥
embeddings = manager.get_embeddings(adata)
print(f"ç»†èƒåµŒå…¥ç»´åº¦: {embeddings.shape}")

# 4. å°†åµŒå…¥æ·»åŠ åˆ° adata ç”¨äºä¸‹æ¸¸åˆ†æ
adata.obsm['X_scgpt'] = embeddings

# 5. ä½¿ç”¨åµŒå…¥è¿›è¡Œèšç±»å’Œå¯è§†åŒ–
sc.pp.neighbors(adata, use_rep='X_scgpt')
sc.tl.umap(adata)
sc.pl.umap(adata, color=['total_counts', 'n_genes_by_counts'])
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æ•™ç¨‹

### 1. åŸºæœ¬ä½¿ç”¨ - ç»†èƒåµŒå…¥

#### æ–¹æ³• 1: ä½¿ç”¨ SCLLMManager (æ¨è)

```python
import omicverse as ov
import scanpy as sc

# åŠ è½½æ•°æ®
adata = sc.read_h5ad("single_cell_data.h5ad")

# åˆ›å»ºç®¡ç†å™¨
manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="/path/to/scgpt/model"
)

# è·å–ç»†èƒåµŒå…¥
embeddings = manager.get_embeddings(adata)

# æ·»åŠ åˆ° adata ä¸­
adata.obsm['X_scgpt'] = embeddings

# ä¸‹æ¸¸åˆ†æ
sc.pp.neighbors(adata, use_rep='X_scgpt')
sc.tl.umap(adata)
sc.pl.umap(adata, color=['total_counts', 'n_genes_by_counts'])
```

#### æ–¹æ³• 2: ä¾¿æ·å‡½æ•°

```python
# ç›´æ¥åŠ è½½æ¨¡å‹
model = ov.external.scllm.load_scgpt("/path/to/model")
embeddings = model.get_embeddings(adata)

# ä¸€è¡Œä»£ç è·å–åµŒå…¥
embeddings = ov.external.scllm.load_scgpt("/path/to/model").get_embeddings(adata)
```

### 2. ç»†èƒç±»å‹æ³¨é‡Š - å®Œæ•´å·¥ä½œæµ

#### æ•°æ®å‡†å¤‡

```python
# åŠ è½½å‚è€ƒæ•°æ® (å¸¦ç»†èƒç±»å‹æ ‡æ³¨)
reference_adata = sc.read_h5ad("reference_with_celltypes.h5ad")
print(f"ç»†èƒç±»å‹: {reference_adata.obs['celltype'].unique()}")

# åŠ è½½æŸ¥è¯¢æ•°æ® (å¾…é¢„æµ‹)
query_adata = sc.read_h5ad("query_data.h5ad")
print(f"æŸ¥è¯¢æ•°æ®: {query_adata.n_obs} ç»†èƒ")
```

#### æ¨¡å‹å¾®è°ƒ

```python
from sklearn.model_selection import train_test_split

# æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°
result = ov.external.scllm.fine_tune_scgpt(
    train_adata=reference_adata,
    model_path="/path/to/pretrained/scgpt",
    save_path="/path/to/finetuned_model",
    epochs=15,
    batch_size=32,
    lr=1e-4,
    validation_split=0.2
)
print(f"å¾®è°ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {result['results']['best_accuracy']:.4f}")

# æ–¹æ³• 2: æ‰‹åŠ¨æ§åˆ¶
# åˆ†å‰²æ•°æ®
train_idx, val_idx = train_test_split(
    range(reference_adata.n_obs),
    test_size=0.2,
    stratify=reference_adata.obs['celltype'],
    random_state=42
)

train_adata = reference_adata[train_idx].copy()
val_adata = reference_adata[val_idx].copy()

# åˆ›å»ºç®¡ç†å™¨å¹¶å¾®è°ƒ
manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="/path/to/pretrained/scgpt"
)

fine_tune_results = manager.fine_tune(
    train_adata=train_adata,
    valid_adata=val_adata,
    epochs=20,
    batch_size=64,
    lr=5e-5
)

# ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹
manager.save_model("/path/to/finetuned_model")
```

#### ç»†èƒç±»å‹é¢„æµ‹

```python
# æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°
results = ov.external.scllm.predict_celltypes_workflow(
    query_adata=query_adata,
    finetuned_model_path="/path/to/finetuned_model",
    save_predictions=True
)

print("é¢„æµ‹å®Œæˆ!")
print(f"é¢„æµ‹çš„ç»†èƒç±»å‹: {np.unique(results['predicted_celltypes'])}")
print("ç»†èƒç±»å‹åˆ†å¸ƒ:")
print(query_adata.obs['predicted_celltype'].value_counts())

# æ–¹æ³• 2: æ‰‹åŠ¨æ§åˆ¶
manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="/path/to/finetuned_model"
)

# åŠ è½½ç»†èƒç±»å‹æ˜ å°„
manager.model.load_celltype_mapping("/path/to/finetuned_model")

# é¢„æµ‹
prediction_results = manager.model.predict_celltypes(query_adata)

# æ·»åŠ ç»“æœ
query_adata.obs['predicted_celltype'] = prediction_results['predicted_celltypes']
query_adata.obs['predicted_celltype_id'] = prediction_results['predictions']
```

#### ç«¯åˆ°ç«¯æ³¨é‡Šå·¥ä½œæµ

```python
# ä¸€æ¬¡æ€§å®Œæˆå¾®è°ƒå’Œé¢„æµ‹
results = ov.external.scllm.end_to_end_scgpt_annotation(
    reference_adata=reference_adata,
    query_adata=query_adata,
    pretrained_model_path="/path/to/pretrained/scgpt",
    save_finetuned_path="/path/to/finetuned_model",
    epochs=15,
    batch_size=32,
    lr=1e-4,
    validation_split=0.2
)

print("ç«¯åˆ°ç«¯æµç¨‹å®Œæˆ!")
print(f"å¾®è°ƒæœ€ä½³å‡†ç¡®ç‡: {results['fine_tune_results']['best_accuracy']:.4f}")
print(f"é¢„æµ‹äº† {len(results['prediction_results']['predicted_celltypes'])} ä¸ªç»†èƒ")
```

### 3. æ‰¹æ¬¡ç§¯åˆ† (Integration) - å»é™¤æ‰¹æ¬¡æ•ˆåº”

#### æ ¸å¿ƒæŠ€æœ¯

scGPT Integration ä½¿ç”¨å¤šç§å…ˆè¿›æŠ€æœ¯ï¼š

1. **DAB (Domain Adversarial Batch)** - åŸŸå¯¹æŠ—æ‰¹æ¬¡æ ¡æ­£
2. **DSBN (Domain-Specific Batch Normalization)** - åŸŸç‰¹å¼‚æ€§æ‰¹æ¬¡å½’ä¸€åŒ–  
3. **ECS (Elastic Cell Similarity)** - å¼¹æ€§ç»†èƒç›¸ä¼¼æ€§
4. **GEPC (Gene Expression Prediction for Cells)** - ç»†èƒåŸºå› è¡¨è¾¾é¢„æµ‹
5. **æ›´é«˜çš„æ©ç æ¯”ä¾‹** (0.4 vs 0.0)

#### æ•°æ®å‡†å¤‡

```python
# åŠ è½½è®­ç»ƒæ•°æ® (åŒ…å«æ‰¹æ¬¡ä¿¡æ¯)
train_adata = sc.read_h5ad("train_with_batches.h5ad")
query_adata = sc.read_h5ad("query_with_batches.h5ad")

# æ£€æŸ¥æ‰¹æ¬¡ä¿¡æ¯
print("è®­ç»ƒæ•°æ®æ‰¹æ¬¡åˆ†å¸ƒ:")
print(train_adata.obs['batch'].value_counts())
print("æŸ¥è¯¢æ•°æ®æ‰¹æ¬¡åˆ†å¸ƒ:")
print(query_adata.obs['batch'].value_counts())
```

#### è®­ç»ƒç§¯åˆ†æ¨¡å‹

```python
# æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°
result = ov.external.scllm.train_integration_scgpt(
    train_adata=train_adata,
    model_path="/path/to/pretrained/scgpt",
    batch_key="batch",
    save_path="integration_model",
    epochs=20,
    mask_ratio=0.4,  # Integration ä½¿ç”¨æ›´é«˜çš„æ©ç æ¯”ä¾‹
    do_dab=True,     # å¯ç”¨åŸŸå¯¹æŠ—æ‰¹æ¬¡æ ¡æ­£
    do_mvc=True,     # å¯ç”¨ GEPC
    do_ecs=True,     # å¯ç”¨å¼¹æ€§ç»†èƒç›¸ä¼¼æ€§
    domain_spec_batchnorm=True,  # å¯ç”¨ DSBN
    dab_weight=1.0,
    ecs_weight=10.0,
    gepc_weight=1.0
)

# æ–¹æ³• 2: è¯¦ç»†æ§åˆ¶
from sklearn.model_selection import train_test_split

# åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
train_idx, val_idx = train_test_split(
    range(train_adata.n_obs),
    test_size=0.2,
    stratify=train_adata.obs['batch'],
    random_state=42
)

train_split = train_adata[train_idx].copy()
val_split = train_adata[val_idx].copy()

# åˆ›å»ºç®¡ç†å™¨å¹¶è®­ç»ƒ
manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="/path/to/pretrained/scgpt"
)

integration_results = manager.model.train_integration(
    train_adata=train_split,
    valid_adata=val_split,
    batch_key="batch",
    epochs=25,
    batch_size=32,
    lr=1e-4,
    mask_ratio=0.4,
    # Integration ç‰¹å®šå‚æ•°
    do_dab=True,
    do_mvc=True,
    do_ecs=True,
    domain_spec_batchnorm=True,
    dab_weight=1.0,
    ecs_weight=10.0,
    gepc_weight=1.0
)

print(f"Integration è®­ç»ƒå®Œæˆ! æœ€ä½³æŸå¤±: {integration_results['best_loss']:.4f}")

# ä¿å­˜æ¨¡å‹
manager.save_model("my_integration_model")
```

#### æ‰§è¡Œæ‰¹æ¬¡ç§¯åˆ†

```python
# æ–¹æ³• 1: ä½¿ç”¨ä¾¿æ·å‡½æ•°
results = ov.external.scllm.integrate_batches_workflow(
    query_adata=query_adata,
    integration_model_path="integration_model",
    batch_key="batch"
)

# ç§¯åˆ†åçš„åµŒå…¥å·²è‡ªåŠ¨æ·»åŠ åˆ° query_adata.obsm['X_scgpt_integrated']

# æ–¹æ³• 2: æ‰‹åŠ¨æ§åˆ¶
integration_manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="my_integration_model"
)

# æ‰§è¡Œç§¯åˆ†
integration_results = integration_manager.model.predict(
    query_adata, 
    task="integration",
    batch_key="batch",
    mask_ratio=0.4
)

# è·å–ç§¯åˆ†åçš„åµŒå…¥
integrated_embeddings = integration_results['embeddings']
query_adata.obsm['X_scgpt_integrated'] = integrated_embeddings
```

#### ç«¯åˆ°ç«¯ç§¯åˆ†å·¥ä½œæµ

```python
# ä¸€é”®å®Œæˆè®­ç»ƒå’Œç§¯åˆ†
results = ov.external.scllm.end_to_end_scgpt_integration(
    train_adata=train_adata,
    query_adata=query_adata,
    pretrained_model_path="/path/to/pretrained/scgpt",
    batch_key="batch",
    save_integration_path="scgpt_integration_model",
    epochs=20,
    validation_split=0.2,
    # Integration ç‰¹å®šå‚æ•°
    mask_ratio=0.4,
    do_dab=True,
    do_mvc=True, 
    do_ecs=True,
    domain_spec_batchnorm=True
)

print(f"âœ… Integration å®Œæˆ!")
print(f"è®­ç»ƒæŸå¤±: {results['train_results']['best_loss']:.4f}")
print(f"ç§¯åˆ†ç»†èƒæ•°: {results['integration_results']['integration_stats']['total_cells']}")
```

#### ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„æ‰¹æ¬¡ç§¯åˆ†

```python
# å¦‚æœåªæœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨åå¤„ç†æ–¹æ³•
results = ov.external.scllm.integrate_with_scgpt(
    query_adata=query_adata,
    model_path="/path/to/pretrained/scgpt",
    batch_key="batch",
    correction_method="combat",  # å¯é€‰: 'combat', 'mnn', 'center_scale', 'none'
    save_embeddings=True
)

# ç§¯åˆ†ç»“æœä¿å­˜åœ¨ query_adata.obsm['X_scgpt_integrated']
```

### 4. ç»“æœåˆ†æå’Œå¯è§†åŒ–

#### è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–

```python
import matplotlib.pyplot as plt

# å¯è§†åŒ–è®­ç»ƒå†å²
history = fine_tune_results['training_history']

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

# æŸå¤±æ›²çº¿
ax1.plot(history['train_loss'], label='Training Loss', color='blue')
ax1.plot(history['val_loss'], label='Validation Loss', color='red')
ax1.set_title('Loss Curves')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss')
ax1.legend()
ax1.grid(True)

# å‡†ç¡®ç‡æ›²çº¿
ax2.plot(history['train_acc'], label='Training Accuracy', color='blue')
ax2.plot(history['val_acc'], label='Validation Accuracy', color='red')
ax2.set_title('Accuracy Curves')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Accuracy')
ax2.legend()
ax2.grid(True)

plt.tight_layout()
plt.show()
```

#### ç»†èƒç±»å‹é¢„æµ‹ç»“æœå¯è§†åŒ–

```python
import seaborn as sns

# ç»†èƒç±»å‹åˆ†å¸ƒ
plt.figure(figsize=(10, 6))
celltype_counts = query_adata.obs['predicted_celltype'].value_counts()
sns.barplot(y=celltype_counts.index, x=celltype_counts.values, palette='viridis')
plt.title('Predicted Cell Type Distribution')
plt.xlabel('Number of Cells')
plt.ylabel('Cell Type')
plt.tight_layout()
plt.show()

# UMAP å¯è§†åŒ–
if 'X_scgpt' in query_adata.obsm:
    sc.pp.neighbors(query_adata, use_rep='X_scgpt')
    sc.tl.umap(query_adata)
    
    sc.pl.umap(query_adata, color='predicted_celltype', 
               title='scGPT Predicted Cell Types',
               palette='tab20')
```

#### æ‰¹æ¬¡ç§¯åˆ†æ•ˆæœè¯„ä¼°

```python
# å¯è§†åŒ–æ‰¹æ¬¡æ··åˆåº¦
sc.pl.umap(query_adata, color='batch', title='After Integration')

# è®¡ç®—æ‰¹æ¬¡æ··åˆæŒ‡æ ‡ (éœ€è¦å®‰è£… scib åŒ…)
try:
    import scib
    
    # æ‰¹æ¬¡æ ¡æ­£æŒ‡æ ‡
    silhouette_batch = scib.me.silhouette_batch(
        query_adata.obsm['X_scgpt_integrated'], 
        query_adata.obs['batch']
    )
    
    # ç”Ÿç‰©å­¦ä¿å­˜æŒ‡æ ‡ (å¦‚æœæœ‰ç»†èƒç±»å‹ä¿¡æ¯)
    if 'celltype' in query_adata.obs:
        ari_celltype = scib.me.ari(
            query_adata.obs['celltype'], 
            query_adata.obs['celltype']  # æˆ–èšç±»ç»“æœ
        )
        print(f"ARI (Cell Type): {ari_celltype:.3f}")
    
    print(f"Silhouette Batch: {silhouette_batch:.3f}")
    
except ImportError:
    print("å®‰è£… scib åŒ…ä»¥è·å¾—æ›´å¤šè¯„ä¼°æŒ‡æ ‡: pip install scib")

# ç®€å•çš„æ‰¹æ¬¡æ··åˆåº¦è¯„ä¼°
from sklearn.neighbors import NearestNeighbors

embeddings = query_adata.obsm['X_scgpt_integrated']
batches = query_adata.obs['batch'].values

# è®¡ç®—æ¯ä¸ªç»†èƒæœ€è¿‘é‚»ä¸­ä¸åŒæ‰¹æ¬¡çš„æ¯”ä¾‹
nn = NearestNeighbors(n_neighbors=50)
nn.fit(embeddings)
distances, indices = nn.kneighbors(embeddings)

batch_mixing_scores = []
for i, cell_batch in enumerate(batches):
    neighbor_batches = batches[indices[i]]
    different_batch_ratio = (neighbor_batches != cell_batch).mean()
    batch_mixing_scores.append(different_batch_ratio)

print(f"å¹³å‡æ‰¹æ¬¡æ··åˆåº¦: {np.mean(batch_mixing_scores):.3f}")
```

## âš™ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰æ¨¡å‹é…ç½®

```python
from omicverse.external.scllm import ModelConfig

# è‡ªå®šä¹‰æ¨¡å‹é…ç½®
custom_config = ModelConfig(
    embsize=256,      # åµŒå…¥ç»´åº¦
    nhead=4,          # æ³¨æ„åŠ›å¤´æ•°
    nlayers=6,        # Transformer å±‚æ•°
    dropout=0.1,      # Dropout ç‡
    n_bins=51,        # è¡¨è¾¾å€¼åˆ†ç®±æ•°
    max_seq_len=3001  # æœ€å¤§åºåˆ—é•¿åº¦
)

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
manager = ov.external.scllm.SCLLMManager(
    model_type="scgpt",
    model_path="/path/to/model",
    **custom_config.to_dict()
)
```

### ä»»åŠ¡ç‰¹å®šé…ç½®

```python
from omicverse.external.scllm import TaskConfig

# è·å–é¢„å®šä¹‰çš„ä»»åŠ¡é…ç½®
annotation_config = TaskConfig.get_task_config("annotation")
integration_config = TaskConfig.get_task_config("integration")
generation_config = TaskConfig.get_task_config("generation")

# å¾®è°ƒæ¨¡å‹ä½¿ç”¨ä»»åŠ¡é…ç½®
results = manager.fine_tune(
    train_adata=train_data,
    valid_adata=valid_data,
    task="annotation",
    **annotation_config
)
```

### é›†æˆå‚æ•°è¯¦è§£

```python
# Integration ç‰¹å®šå‚æ•°
integration_results = manager.model.train_integration(
    train_adata=train_adata,
    batch_key="batch",
    
    # åŸºæœ¬è®­ç»ƒå‚æ•°
    epochs=25,              # Integration é€šå¸¸éœ€è¦æ›´å¤šè½®æ¬¡
    batch_size=32,          # æ‰¹é‡å¤§å°
    lr=1e-4,               # å­¦ä¹ ç‡
    
    # Integration æ ¸å¿ƒå‚æ•°
    mask_ratio=0.4,         # æ©ç æ¯”ä¾‹ (Integration ç”¨ 0.4, Annotation ç”¨ 0.0)
    
    # æŠ€æœ¯å¼€å…³
    do_dab=True,            # åŸŸå¯¹æŠ—æ‰¹æ¬¡æ ¡æ­£
    do_mvc=True,            # Gene Expression Prediction for Cells  
    do_ecs=True,            # å¼¹æ€§ç»†èƒç›¸ä¼¼æ€§
    domain_spec_batchnorm=True,  # åŸŸç‰¹å¼‚æ€§æ‰¹æ¬¡å½’ä¸€åŒ–
    
    # æŸå¤±æƒé‡
    dab_weight=1.0,         # DAB æŸå¤±æƒé‡
    ecs_weight=10.0,        # ECS æŸå¤±æƒé‡ (é€šå¸¸è¾ƒé«˜)
    gepc_weight=1.0,        # GEPC æŸå¤±æƒé‡
)
```

## ğŸ“ ä½¿ç”¨æ³¨æ„äº‹é¡¹

### æ¨¡å‹æ–‡ä»¶è¦æ±‚

æ¨¡å‹ç›®å½•åº”åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

```
your_model_directory/
â”œâ”€â”€ vocab.json          # è¯æ±‡è¡¨æ–‡ä»¶ (å¿…éœ€)
â”œâ”€â”€ best_model.pt       # æ¨¡å‹æƒé‡æ–‡ä»¶ (å¿…éœ€)
â””â”€â”€ args.json           # æ¨¡å‹é…ç½®æ–‡ä»¶ (å¯é€‰ï¼Œä½†æ¨è)
```

### æ•°æ®è¦æ±‚

- **è¾“å…¥**: AnnData å¯¹è±¡ï¼ŒåŒ…å«åŸºå› è¡¨è¾¾æ•°æ®
- **åŸºå› å‘½å**: ç¡®ä¿åŸºå› åç§°ä¸æ¨¡å‹è¯æ±‡è¡¨åŒ¹é…
- **é¢„å¤„ç†**: ç³»ç»Ÿä¼šè‡ªåŠ¨è¿›è¡Œå¿…è¦çš„é¢„å¤„ç† (å½’ä¸€åŒ–ã€åˆ†ç®±ç­‰)
- **æ‰¹æ¬¡ä¿¡æ¯**: Integration ä»»åŠ¡éœ€è¦åœ¨ `adata.obs` ä¸­åŒ…å«æ‰¹æ¬¡æ ‡ç­¾

### æ•°æ®é¢„å¤„ç†æ™ºèƒ½æ£€æµ‹

ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®çš„å½’ä¸€åŒ–çŠ¶æ€ï¼š

```python
# ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹ä»¥ä¸‹æƒ…å†µï¼š
# - æ•°æ®æ˜¯å¦å·²å½’ä¸€åŒ–åˆ° 10k æˆ– 1M
# - æ•°æ®æ˜¯å¦å·²ç» log å˜æ¢
# - æ•°æ®æ˜¯å¦å·²ç»è¿‡é¢„å¤„ç†

# ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨æ§åˆ¶ï¼š
manager.get_embeddings(
    adata, 
    skip_normalization=True,    # è·³è¿‡å½’ä¸€åŒ–
    force_normalization=True,   # å¼ºåˆ¶å½’ä¸€åŒ–
    data_is_raw=False          # æŒ‡å®šæ•°æ®ä¸æ˜¯åŸå§‹è®¡æ•°
)
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### 1. æ¨¡å‹åŠ è½½é—®é¢˜

```python
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
import os
model_path = "/path/to/your/model"

required_files = ["vocab.json", "model.pt", "args.json"]
for file in required_files:
    file_path = os.path.join(model_path, file)
    if os.path.exists(file_path):
        print(f"âœ“ {file} exists")
    else:
        print(f"âŒ {file} missing")
```

#### 2. åŸºå› åŒ¹é…æ£€æŸ¥

```python
# æ£€æŸ¥æ•°æ®ä¸è¯æ±‡è¡¨çš„åŒ¹é…åº¦
manager = ov.external.scllm.SCLLMManager("scgpt", model_path)

vocab_genes = set(manager.model.vocab.get_itos())
data_genes = set(adata.var_names)
overlap = vocab_genes.intersection(data_genes)

print(f"è¯æ±‡è¡¨åŸºå› æ•°: {len(vocab_genes)}")
print(f"æ•°æ®åŸºå› æ•°: {len(data_genes)}")
print(f"é‡å åŸºå› æ•°: {len(overlap)}")
print(f"åŒ¹é…ç‡: {len(overlap)/len(data_genes)*100:.1f}%")

if len(overlap) / len(data_genes) < 0.5:
    print("âš ï¸  åŸºå› åŒ¹é…ç‡è¾ƒä½ï¼Œå¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½")
```

#### 3. å†…å­˜ä¼˜åŒ–

```python
import torch

# æ£€æŸ¥ GPU çŠ¶æ€
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name()}")
    print(f"GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    # å¯¹äºå†…å­˜è¾ƒå°çš„ GPUï¼Œä½¿ç”¨æ›´å°çš„æ‰¹é‡å¤§å°
    batch_size = 16 if torch.cuda.get_device_properties(0).total_memory < 8e9 else 32
else:
    print("ä½¿ç”¨ CPUï¼Œå»ºè®® batch_size=8")
    batch_size = 8

# åœ¨å¾®è°ƒæ—¶ä½¿ç”¨è°ƒæ•´åçš„æ‰¹é‡å¤§å°
fine_tune_results = manager.fine_tune(
    train_adata=train_adata,
    batch_size=batch_size,
    # å…¶ä»–å‚æ•°...
)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®é¢„å¤„ç†ä¼˜åŒ–

```python
# é¢„å…ˆè¿‡æ»¤ä½è´¨é‡ç»†èƒå’ŒåŸºå› 
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

# é€‰æ‹©é«˜å˜åŸºå› ä»¥å‡å°‘è®¡ç®—é‡
sc.pp.highly_variable_genes(adata, n_top_genes=3000)
adata_hvg = adata[:, adata.var.highly_variable].copy()
```

### 2. æ‰¹é‡å¤„ç†

```python
# å¯¹äºå¤šä¸ªæ•°æ®é›†çš„æ‰¹é‡å¤„ç†
datasets = ["dataset1.h5ad", "dataset2.h5ad", "dataset3.h5ad"]
results = []

for dataset_path in datasets:
    adata = sc.read_h5ad(dataset_path)
    result = manager.model.predict_celltypes(adata)
    results.append(result)
    print(f"å®Œæˆ {dataset_path}")
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æœ‰ä¸€è‡´çš„æ‰¹æ¬¡æ ‡æ³¨ (å¯¹äº Integration)
- æ‰¹æ¬¡é—´åº”è¯¥æœ‰è¶³å¤Ÿçš„ç»†èƒæ•°é‡
- åŸºå› åç§°åœ¨æ‰€æœ‰æ‰¹æ¬¡é—´ä¿æŒä¸€è‡´

### 2. å‚æ•°è°ƒä¼˜
- **mask_ratio**: Integration é€šå¸¸ä½¿ç”¨ 0.4ï¼Œæ¯” annotation çš„ 0.0 æ›´é«˜
- **epochs**: Integration éœ€è¦æ›´å¤šè®­ç»ƒè½®æ¬¡ (20-30)  
- **loss weights**: ECS æƒé‡é€šå¸¸è®¾ç½®è¾ƒé«˜ (10.0)

### 3. éªŒè¯å’Œè¯„ä¼°
- ä½¿ç”¨éªŒè¯é›†ç›‘æ§è®­ç»ƒè¿‡ç¨‹
- æ£€æŸ¥æ‰¹æ¬¡æ··åˆåº¦å’Œç”Ÿç‰©å­¦ä¿¡æ¯ä¿å­˜
- ä½¿ç”¨ UMAP å¯è§†åŒ–éªŒè¯æ•ˆæœ

## ğŸš€ ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”

| æ–¹æ³• | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **scGPT Integration** | ä¿ç•™ç”Ÿç‰©å­¦ä¿¡æ¯ï¼Œå¤šç§æŠ€æœ¯ç»“åˆ | å¤æ‚æ‰¹æ¬¡æ•ˆåº”ï¼Œå¤§è§„æ¨¡æ•°æ® |
| Harmony | å¿«é€Ÿï¼Œç®€å• | ç®€å•æ‰¹æ¬¡æ•ˆåº” |
| Scanorama | å¤„ç†ä¸åŒæŠ€æœ¯å¹³å° | è·¨å¹³å°æ•´åˆ |
| ComBat | ä¼ ç»Ÿæ–¹æ³•ï¼Œç¨³å®š | ç®€å•çº¿æ€§æ‰¹æ¬¡æ•ˆåº” |

## ğŸ’¡ ä¼˜åŠ¿æ€»ç»“

### ä¸åŸå§‹ scGPT æ•™ç¨‹çš„å¯¹æ¯”

| é¡¹ç›® | åŸå§‹æ–¹æ³• | æ–°æ¥å£ |
|------|---------|--------|
| ä»£ç é•¿åº¦ | 200+ è¡Œ | 3-10 è¡Œ |
| å‚æ•°é…ç½® | æ‰‹åŠ¨è®¾ç½® 30+ å‚æ•° | è‡ªåŠ¨é…ç½® + å¯é€‰è‡ªå®šä¹‰ |
| é”™è¯¯å¤„ç† | ç”¨æˆ·è‡ªè¡Œå¤„ç† | å†…ç½®é”™è¯¯å¤„ç† |
| æ¨¡å‹ç®¡ç† | æ‰‹åŠ¨ç®¡ç†ç»„ä»¶ | ç»Ÿä¸€ç®¡ç†æ¥å£ |
| æ‰©å±•æ€§ | å•ä¸€æ¨¡å‹ | å¤šæ¨¡å‹æ”¯æŒæ¶æ„ |
| ä»»åŠ¡æ”¯æŒ | æ‰‹åŠ¨é…ç½® | é¢„é…ç½®çš„ä»»åŠ¡ç‰¹å®šå‚æ•° |

### ä¸»è¦ä¼˜åŠ¿

1. **å¤§å¹…ç®€åŒ–ä½¿ç”¨**: ä» 200+ è¡Œä»£ç å‡å°‘åˆ°å‡ è¡Œ
2. **ç»Ÿä¸€æ¥å£**: ä¸åŒæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„ API
3. **ä»»åŠ¡å¯¼å‘**: é¢„é…ç½®çš„æœ€ä½³å®è·µå‚æ•°
4. **æ˜“äºæ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡æ”¯æŒæ–°æ¨¡å‹
5. **é”™è¯¯å¤„ç†**: ä¼˜é›…å¤„ç†ä¾èµ–é¡¹é—®é¢˜
6. **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰çš„ scGPT ä½¿ç”¨æ–¹å¼
7. **æ™ºèƒ½é¢„å¤„ç†**: è‡ªåŠ¨æ£€æµ‹æ•°æ®çŠ¶æ€å¹¶é€‚é…

è¿™ä¸ªç»Ÿä¸€çš„æ¥å£è®©ç ”ç©¶äººå‘˜å¯ä»¥ä¸“æ³¨äºç§‘å­¦é—®é¢˜ï¼Œè€Œä¸æ˜¯æŠ€æœ¯ç»†èŠ‚ï¼

## ğŸ“š å®Œæ•´ç¤ºä¾‹è„šæœ¬

### ç»†èƒç±»å‹æ³¨é‡Šå®Œæ•´ç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
scGPT ç»†èƒç±»å‹æ³¨é‡Šå®Œæ•´ç¤ºä¾‹
"""

import omicverse as ov
import scanpy as sc
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def main():
    # 1. åŠ è½½æ•°æ®
    print("ğŸ“š åŠ è½½æ•°æ®...")
    reference_adata = sc.read_h5ad("reference.h5ad")
    query_adata = sc.read_h5ad("query.h5ad")
    
    print(f"å‚è€ƒæ•°æ®: {reference_adata.n_obs} cells Ã— {reference_adata.n_vars} genes")
    print(f"æŸ¥è¯¢æ•°æ®: {query_adata.n_obs} cells Ã— {query_adata.n_vars} genes")
    print(f"ç»†èƒç±»å‹: {reference_adata.obs['celltype'].nunique()} ç§")
    
    # 2. ç«¯åˆ°ç«¯æ³¨é‡Šå·¥ä½œæµ
    print("\nğŸ¯ æ‰§è¡Œç«¯åˆ°ç«¯æ³¨é‡Š...")
    results = ov.external.scllm.end_to_end_scgpt_annotation(
        reference_adata=reference_adata,
        query_adata=query_adata,
        pretrained_model_path="path/to/scgpt/model",
        save_finetuned_path="finetuned_scgpt_model",
        epochs=15,
        batch_size=32,
        lr=1e-4,
        validation_split=0.2
    )
    
    print(f"âœ… æ³¨é‡Šå®Œæˆ!")
    print(f"å¾®è°ƒæœ€ä½³å‡†ç¡®ç‡: {results['fine_tune_results']['best_accuracy']:.4f}")
    print(f"é¢„æµ‹äº† {len(results['prediction_results']['predicted_celltypes'])} ä¸ªç»†èƒ")
    
    # 3. å¯è§†åŒ–ç»“æœ
    print("\nğŸ“Š å¯è§†åŒ–ç»“æœ...")
    
    # ç»†èƒç±»å‹åˆ†å¸ƒ
    import seaborn as sns
    plt.figure(figsize=(10, 6))
    celltype_counts = query_adata.obs['predicted_celltype'].value_counts()
    sns.barplot(y=celltype_counts.index, x=celltype_counts.values, palette='viridis')
    plt.title('Predicted Cell Type Distribution')
    plt.xlabel('Number of Cells')
    plt.ylabel('Cell Type')
    plt.tight_layout()
    plt.savefig('predicted_celltype_distribution.pdf')
    plt.show()
    
    # UMAP å¯è§†åŒ–
    if 'embeddings' in results['prediction_results']:
        query_adata.obsm['X_scgpt'] = results['prediction_results']['embeddings']
        sc.pp.neighbors(query_adata, use_rep='X_scgpt')
        sc.tl.umap(query_adata)
        
        sc.pl.umap(query_adata, color='predicted_celltype', 
                   title='scGPT Predicted Cell Types',
                   save='_scgpt_predictions.pdf')
    
    # 4. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    query_adata.write("query_with_predictions.h5ad")
    
    print("\nğŸ‰ æ³¨é‡Šç¤ºä¾‹å®Œæˆ!")
    return results

if __name__ == "__main__":
    main()
```

### æ‰¹æ¬¡ç§¯åˆ†å®Œæ•´ç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
scGPT Integration å®Œæ•´ç¤ºä¾‹
"""

import omicverse as ov
import scanpy as sc
import pandas as pd
import numpy as np

def integration_example():
    print("ğŸš€ scGPT Integration ç¤ºä¾‹")
    
    # 1. åŠ è½½æ•°æ®
    print("\nğŸ“š åŠ è½½æ•°æ®...")
    train_adata = sc.read_h5ad("train_with_batches.h5ad")
    query_adata = sc.read_h5ad("query_with_batches.h5ad")
    
    print(f"è®­ç»ƒæ•°æ®: {train_adata.n_obs} ç»†èƒ")
    print(f"æŸ¥è¯¢æ•°æ®: {query_adata.n_obs} ç»†èƒ")
    print(f"è®­ç»ƒæ•°æ®æ‰¹æ¬¡: {train_adata.obs['batch'].nunique()}")
    print(f"æŸ¥è¯¢æ•°æ®æ‰¹æ¬¡: {query_adata.obs['batch'].nunique()}")
    
    # 2. ç«¯åˆ°ç«¯ Integration å·¥ä½œæµ
    print("\nğŸ¯ æ‰§è¡Œç«¯åˆ°ç«¯ Integration...")
    results = ov.external.scllm.end_to_end_scgpt_integration(
        train_adata=train_adata,
        query_adata=query_adata,
        pretrained_model_path="path/to/pretrained/scgpt",
        batch_key="batch",
        save_integration_path="scgpt_integration_model",
        epochs=20,
        validation_split=0.2,
        # Integration ç‰¹å®šå‚æ•°
        mask_ratio=0.4,
        do_dab=True,
        do_mvc=True, 
        do_ecs=True,
        domain_spec_batchnorm=True
    )
    
    print(f"âœ… Integration å®Œæˆ!")
    print(f"è®­ç»ƒæŸå¤±: {results['train_results']['best_loss']:.4f}")
    print(f"ç§¯åˆ†ç»†èƒæ•°: {results['integration_results']['integration_stats']['total_cells']}")
    
    # 3. å¯è§†åŒ– Integration ç»“æœ
    print("\nğŸ“Š å¯è§†åŒ–ç»“æœ...")
    
    # ä½¿ç”¨ç§¯åˆ†åçš„åµŒå…¥è¿›è¡Œ UMAP
    sc.pp.neighbors(query_adata, use_rep='X_scgpt_integrated')
    sc.tl.umap(query_adata)
    
    # å¯è§†åŒ–æ‰¹æ¬¡æ•ˆåº”å»é™¤æ•ˆæœ
    sc.pl.umap(query_adata, color='batch', 
               title='scGPT Integration - Batches',
               save='_scgpt_integration_batches.pdf')
    
    # å¦‚æœæœ‰ç»†èƒç±»å‹ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥å¯è§†åŒ–
    if 'celltype' in query_adata.obs:
        sc.pl.umap(query_adata, color='celltype',
                   title='scGPT Integration - Cell Types', 
                   save='_scgpt_integration_celltypes.pdf')
    
    # 4. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ç»“æœ...")
    query_adata.write("query_integrated.h5ad")
    
    print("\nğŸ‰ Integration ç¤ºä¾‹å®Œæˆ!")
    return results

if __name__ == "__main__":
    integration_example()
```

è¿™ä¸ªç»Ÿä¸€çš„æ–‡æ¡£æ¶µç›–äº† scGPT çš„æ‰€æœ‰ä¸»è¦åŠŸèƒ½ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–¹æ³•å’Œå‚æ•°é…ç½®ï¼