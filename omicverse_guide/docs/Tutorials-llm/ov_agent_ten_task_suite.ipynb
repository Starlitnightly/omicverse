{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd894374",
   "metadata": {},
   "source": [
    "# ov.Agent Ten-Task Regression Suite\n",
    "\n",
    "This notebook instantiates **ov.Agent** once and then reuses it across ten composite tasks that span end-to-end processing, multi-batch integration, trajectory inference, multiome alignment, tumor microenvironment analytics, and spatial modeling. Each task pairs a carefully worded ov.Agent prompt with lightweight validation hooks so you can quickly benchmark whether the agent still covers the relevant skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36ee7a",
   "metadata": {},
   "source": [
    "## Notebook structure\n",
    "\n",
    "1. Bootstrap ov.Agent with the same diagnostics used in `Tutorials-llm/t_ov_agent_pbmc3k.ipynb`.\n",
    "2. Load the [`ov_agent_tutorial_data_sources.md`](../../OvIntelligence/ov_agent_tutorial_data_sources.md) manifest so every task can remind you which local `.h5ad` files or remote links must be staged.\n",
    "3. Define ten task specs (prompt + datasets + keyword checks) and a helper `run_task` wrapper that:\n",
    "   - prints data reminders via `ensure_data(...)`\n",
    "   - calls `agent.chat(prompt)`\n",
    "   - records simple keyword-based health checks in `TASK_LOG`\n",
    "4. Optionally loop through all specs to stress-test ov.Agent end to end, then summarize pass/fail status in a scoreboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, omicverse as ov\n",
    "print(sys.executable)\n",
    "print('omicverse', getattr(ov, '__version__', 'unknown'), ov.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "import scanpy as sc\n",
    "import omicverse as ov\n",
    "\n",
    "print('OmicVerse version:', getattr(ov, '__version__', 'unknown'))\n",
    "print('Supported models:', ov.list_supported_models())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '')\n",
    "\n",
    "if not (OPENAI_API_KEY or ANTHROPIC_API_KEY or GEMINI_API_KEY):\n",
    "    print('Warning: set OPENAI_API_KEY / ANTHROPIC_API_KEY / GEMINI_API_KEY before running live ov.Agent requests.')\n",
    "\n",
    "model_id = 'gpt-5'\n",
    "api_key = OPENAI_API_KEY or ANTHROPIC_API_KEY or GEMINI_API_KEY\n",
    "agent = ov.Agent(model=model_id, api_key=api_key)\n",
    "agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f14b8",
   "metadata": {},
   "source": [
    "## Data source manifest helper\n",
    "\n",
    "`ensure_data(...)` looks up tutorial references inside `OvIntelligence/ov_agent_tutorial_data_sources.md` so that each task can remind you which `.h5ad` or model files should be prepared ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a792875",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_PATH = Path('OvIntelligence/ov_agent_tutorial_data_sources.md')\n",
    "\n",
    "def _parse_data_source_table():\n",
    "    mapping = {}\n",
    "    if not DATA_SOURCE_PATH.exists():\n",
    "        return mapping\n",
    "    current_section = None\n",
    "    for raw_line in DATA_SOURCE_PATH.read_text().splitlines():\n",
    "        line = raw_line.strip()\n",
    "        if line.startswith('## '):\n",
    "            current_section = line[3:].strip()\n",
    "            continue\n",
    "        if not line.startswith('| `Tutorial'):\n",
    "            continue\n",
    "        parts = [p.strip() for p in line.strip('|').split('|')]\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        tutorial_ref = parts[0].strip('`')\n",
    "        mapping[tutorial_ref] = {\n",
    "            'files': parts[1],\n",
    "            'size': parts[2],\n",
    "            'hint': parts[3],\n",
    "            'section': current_section,\n",
    "        }\n",
    "    return mapping\n",
    "\n",
    "DATA_SOURCES = _parse_data_source_table()\n",
    "print(f'Loaded {len(DATA_SOURCES)} tutorial rows from {DATA_SOURCE_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_data(tutorial_refs):\n",
    "    \"\"\"Print local-file reminders for the given tutorial references.\"\"\"\n",
    "    refs = tutorial_refs\n",
    "    if isinstance(refs, str):\n",
    "        refs = [refs]\n",
    "    display(Markdown('**Data reminders**'))\n",
    "    for ref in refs:\n",
    "        info = DATA_SOURCES.get(ref)\n",
    "        if info:\n",
    "            display(Markdown(\n",
    "                f'- `{ref}` (section: {info.get(\"section\", \"n/a\")}):\n",
    "'\n",
    "                f'  - Files/models: {info.get(\"files\", \"see tutorial\")}\n",
    "'\n",
    "                f'  - Approx. size: {info.get(\"size\", \"n/a\")}\n",
    "'\n",
    "                f'  - Source hint: {info.get(\"hint\", \"see tutorial\")}'\n",
    "            ))\n",
    "        else:\n",
    "            display(Markdown(f'- `{ref}`: not found in manifest — consult the tutorial README.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857fe2a",
   "metadata": {},
   "source": [
    "## Task catalog\n",
    "\n",
    "Each entry specifies a natural-language ov.Agent prompt, the tutorial references whose data are required, and lightweight keyword checks. The prompts intentionally call out the tutorials so the agent can leverage progressive skill disclosure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5502cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_SPECS = [\n",
    "    {\n",
    "        'name': 'PBMC 5k/8k FASTQ → QC → cluster-stability benchmarking',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_alignment_1k.ipynb',\n",
    "            'Tutorials-single/t_preprocess.ipynb',\n",
    "            'Tutorials-single/t_cluster.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"You are ov.Agent orchestrating an end-to-end PBMC 5k/8k workflow.\n",
    "1. Start from raw 10x FASTQs and reuse the kb-python alignment recipe from `Tutorials-single/t_alignment_1k.ipynb` to output `adata.h5ad` count matrices.\n",
    "2. Run the PBMC3k-style QC + HVG + scaling pipeline from `Tutorials-single/t_preprocess.ipynb`, citing the concrete Scanpy calls and recommended thresholds.\n",
    "3. Stress-test Leiden, Louvain, Gaussian mixture, and LDA clustering heads at multiple resolutions as shown in `Tutorials-single/t_cluster.ipynb`, summarize UMAP drift scores for each head, and recommend the most stable resolution.\n",
    "4. Return the sequence of code/CLI blocks plus a markdown table that lists resolution, cluster head, UMAP drift (0–1), and stability notes.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions kb-python alignment', 'keywords': ['kb-python', 'FASTQ']},\n",
    "            {'description': 'Reports UMAP drift or stability table', 'keywords': ['UMAP', 'drift']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Pancreas multi-study merge with SIMBA embeddings',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_single_batch.ipynb',\n",
    "            'Tutorials-single/t_simba.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Fuse the Baron, Segerstolpe, and Muraro pancreas scRNA-seq cohorts.\n",
    "- Follow the donor harmonization guidance from `Tutorials-single/t_single_batch.ipynb` to align preprocessing choices (normalization, HVGs, regressions).\n",
    "- Apply the SIMBA graph-embedding pipeline from `Tutorials-single/t_simba.ipynb`, explicitly showing the commands that build the heterogeneous graph, train the embedding, and project to 2D.\n",
    "- Provide before/after UMAPs (describe filenames), kBET, and silhouette metrics while commenting on endocrine vs. exocrine separation.\n",
    "- Deliver a concise explanation of how to export the learned embeddings for downstream classifiers.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'References SIMBA graph embedding', 'keywords': ['SIMBA', 'embedding']},\n",
    "            {'description': 'Includes kBET or silhouette metrics', 'keywords': ['kBET', 'silhouette']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Paul15 hematopoietic trajectories with MetaTiME diagnostics',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_traj.ipynb',\n",
    "            'Tutorials-single/t_metatime.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Using Paul15-like hematopoietic data:\n",
    "1. Run diffusion maps, PAGA, and Palantir/VIA as described in `Tutorials-single/t_traj.ipynb` to recover megakaryocyte vs. lymphoid branches.\n",
    "2. Identify root/terminal states, compute pseudotime, and extract branch marker tables for at least two fates.\n",
    "3. Invoke the MetaTiME checklist from `Tutorials-single/t_metatime.ipynb` to score cycling programs and flag any branch-specific oscillations.\n",
    "4. Summarize outputs as (a) code blocks, (b) descriptions of saved plots, and (c) a markdown summary of pseudotime milestones.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions diffusion/Palantir', 'keywords': ['diffusion', 'Palantir']},\n",
    "            {'description': 'Cites MetaTiME diagnostics', 'keywords': ['MetaTiME', 'cycling']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'PBMC Multiome 10k GLUE + MOFA factor discovery',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_mofa_glue.ipynb',\n",
    "            'Tutorials-single/t_mofa.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Perform cross-modal alignment for PBMC Multiome 10k.\n",
    "- Pair RNA and ATAC embeddings with GLUE (per `Tutorials-single/t_mofa_glue.ipynb`) and report the path to the paired cell metadata.\n",
    "- Train MOFA on the matched matrices (see `Tutorials-single/t_mofa.ipynb` and `t_mofa_glue`) and differentiate shared, RNA-only, and ATAC-only factors with variance explained tables.\n",
    "- Highlight at least one IFN-response and one chromatin-accessibility-specific factor, including top marker genes/peaks.\n",
    "- Provide code snippets plus interpretation bullets for every factor category.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'GLUE pairing mentioned', 'keywords': ['GLUE', 'pair']},\n",
    "            {'description': 'MOFA factor summaries provided', 'keywords': ['MOFA', 'factor']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'PBMC 5k scATAC label transfer via GLUE embeddings',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_anno_trans.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Transfer PBMC RNA annotations onto PBMC 5k scATAC cells.\n",
    "- Load the GLUE-derived RNA/ATAC embeddings (`data/analysis_lymph/rna-emb.h5ad` and `data/analysis_lymph/atac-emb.h5ad`).\n",
    "- Build the cross-modal KNN graph exactly as outlined in `Tutorials-single/t_anno_trans.ipynb` and migrate labels with confidence scores.\n",
    "- Report per-cluster agreement, flag potential mismatches, and describe how to visualize transferred labels on an ATAC UMAP.\n",
    "- Return both the python commands and a markdown table of cluster vs. confidence.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions cross-modal KNN transfer', 'keywords': ['KNN', 'transfer']},\n",
    "            {'description': 'Reports confidence per cluster', 'keywords': ['confidence', 'cluster']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Tumor microenvironment ligand–receptor diagnostics (CellPhoneDBViz)',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_cellphonedb.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"For a treated vs. untreated tumor microenvironment dataset:\n",
    "- Follow `Tutorials-single/t_cellphonedb.ipynb` to format metadata, run CellPhoneDB, and visualize ligand–receptor usage.\n",
    "- Emphasize exhausted T cells vs. M2 macrophages, reporting top LR pairs per condition along with effect sizes or p-values.\n",
    "- Describe how to generate both heatmaps and chord diagrams using CellPhoneDBViz utilities, including filenames for saved plots.\n",
    "- Provide guidance on interpreting shifts between conditions.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'CellPhoneDB workflow described', 'keywords': ['CellPhoneDB', 'ligand']},\n",
    "            {'description': 'Mentions visualization artifacts', 'keywords': ['heatmap', 'chord']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'MetaTiME-driven immune microenvironment annotation',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_metatime.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Annotate tumor-infiltrating immune cells with MetaTiME.\n",
    "- Optionally remove malignant cells using inferCNV outputs, then recompute neighbors in SCVI space per `Tutorials-single/t_metatime.ipynb`.\n",
    "- Run MetaTiME scoring, rank meta-components per cluster, and interpret dominant immune states (e.g., IFN-high, cycling, antigen-presenting).\n",
    "- Output code for preprocessing + scoring and finish with a markdown report that lists cluster → top meta-component plus interpretation.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions MetaTiME scoring', 'keywords': ['MetaTiME', 'meta-component']},\n",
    "            {'description': 'References SCVI neighbors/inferCNV filtering', 'keywords': ['SCVI', 'inferCNV']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'CEFCON driver regulator discovery',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_cellfate.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Discover lineage-specific driver regulators with CEFCON.\n",
    "- Use the preprocessing + prior network setup described in `Tutorials-single/t_cellfate.ipynb` for Nestorowa/Paul15 hematopoiesis.\n",
    "- Load the NicheNet prior graph, run `ov.single.pyCEFCON`, and export regulon tables for at least two branches (erythroid vs. granulocyte, for example).\n",
    "- Provide tips on parameter tuning (walk length, regularization) and show how to visualize regulator activity heatmaps.\n",
    "- Summarize key regulators per branch in markdown.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions CEFCON run + prior network', 'keywords': ['CEFCON', 'NicheNet']},\n",
    "            {'description': 'Reports regulon or regulator tables', 'keywords': ['regulon', 'regulator']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Precision oncology prioritization (inferCNV + scDrug)',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_scdrug.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Combine inferCNV-based malignant calling with scDrug predictions.\n",
    "- Following `Tutorials-single/t_scdrug.ipynb`, run infercnvpy to separate malignant vs. normal cells and mention the CNV heatmap artifact.\n",
    "- Feed malignant clones into scDrug, compute predicted IC50 values, and rank at least five compounds per clone.\n",
    "- Provide code for exporting the ranking table, plus guidance on cross-referencing copy-number context when interpreting drug hits.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'inferCNV workflow described', 'keywords': ['inferCNV', 'CNV']},\n",
    "            {'description': 'scDrug IC50 ranking reported', 'keywords': ['scDrug', 'IC50']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Spatial pseudo-time + alignment (SpaceFlow + STAligner)',\n",
    "        'datasets': [\n",
    "            'Tutorials-space/t_spaceflow.ipynb',\n",
    "            'Tutorials-space/t_staligner.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Build spatial pseudo-time for Visium DLPFC slice 151676 and align adjacent slices.\n",
    "- Run SpaceFlow exactly as in `Tutorials-space/t_spaceflow.ipynb` to compute embeddings, domains, and pseudo-spatiotemporal maps (pSM), referencing the `151676_filtered_feature_bc_matrix.h5` input.\n",
    "- Feed at least two consecutive slices plus their embeddings into STAligner per `Tutorials-space/t_staligner.ipynb`, enabling the triplet-loss GAT to align cortical layers.\n",
    "- Report output filenames for aligned embeddings and highlight conserved layers across slices in markdown.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'SpaceFlow pseudo-time mentioned', 'keywords': ['SpaceFlow', 'pSM']},\n",
    "            {'description': 'STAligner alignment described', 'keywords': ['STAligner', 'alignment']},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "print(f'{len(TASK_SPECS)} task specs loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2c26e",
   "metadata": {},
   "source": [
    "## Task runner utilities\n",
    "\n",
    "`run_task(...)` displays context, ensures data availability reminders, calls ov.Agent, and stores keyword-check results inside `TASK_LOG` for later summarization. Adjust `RESPONSE_PARSER` if your deployment returns structured JSON instead of plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_LOG = []\n",
    "\n",
    "def evaluate_response_text(response_text, checks):\n",
    "    text = response_text or ''\n",
    "    lower = text.lower()\n",
    "    results = []\n",
    "    for check in checks:\n",
    "        keywords = [kw.lower() for kw in check.get('keywords', [])]\n",
    "        passed = all(kw in lower for kw in keywords)\n",
    "        results.append({\n",
    "            'description': check.get('description', ''),\n",
    "            'keywords': keywords,\n",
    "            'passed': passed,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_task(spec):\n",
    "    display(Markdown(f\"## Task: {spec['name']}\"))\n",
    "    ensure_data(spec.get('datasets', []))\n",
    "    prompt = spec['prompt']\n",
    "    response = agent.chat(prompt)\n",
    "    if isinstance(response, dict):\n",
    "        response_text = json.dumps(response, indent=2)\n",
    "    else:\n",
    "        response_text = str(response)\n",
    "    checks = evaluate_response_text(response_text, spec.get('checks', []))\n",
    "    TASK_LOG.append({\n",
    "        'name': spec['name'],\n",
    "        'timestamp': datetime.utcnow().isoformat() + 'Z',\n",
    "        'checks': checks,\n",
    "        'response_preview': response_text[:2000],\n",
    "    })\n",
    "    display(Markdown('**Response preview**'))\n",
    "    display(Markdown(response_text[:2000]))\n",
    "    display(Markdown('**Check results**'))\n",
    "    for chk in checks:\n",
    "        status = '✅' if chk['passed'] else '❌'\n",
    "        display(Markdown(f\"- {status} {chk['description']} (keywords: {', '.join(chk['keywords'])})\"))\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84a7a1",
   "metadata": {},
   "source": [
    "## Execute the full suite\n",
    "\n",
    "Set `RUN_ALL = True` to launch all ten prompts sequentially. You can also call `run_task(TASK_SPECS[i])` manually for spot checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e015908",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ALL = False\n",
    "\n",
    "if RUN_ALL:\n",
    "    for spec in TASK_SPECS:\n",
    "        run_task(spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93abbdf",
   "metadata": {},
   "source": [
    "### Task 1: PBMC 5k/8k FASTQ → QC → cluster-stability benchmarking\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999639f4",
   "metadata": {},
   "source": [
    "### Task 2: Pancreas multi-study merge with SIMBA embeddings\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc709b48",
   "metadata": {},
   "source": [
    "### Task 3: Paul15 hematopoietic trajectories with MetaTiME diagnostics\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6a0ac",
   "metadata": {},
   "source": [
    "### Task 4: PBMC Multiome 10k GLUE + MOFA factor discovery\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d69f6",
   "metadata": {},
   "source": [
    "### Task 5: PBMC 5k scATAC label transfer via GLUE embeddings\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a76b18",
   "metadata": {},
   "source": [
    "### Task 6: Tumor microenvironment ligand–receptor diagnostics (CellPhoneDBViz)\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b07cda",
   "metadata": {},
   "source": [
    "### Task 7: MetaTiME-driven immune microenvironment annotation\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d838a",
   "metadata": {},
   "source": [
    "### Task 8: CEFCON driver regulator discovery\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d8873",
   "metadata": {},
   "source": [
    "### Task 9: Precision oncology prioritization (inferCNV + scDrug)\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce6b24",
   "metadata": {},
   "source": [
    "### Task 10: Spatial pseudo-time + alignment (SpaceFlow + STAligner)\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6febfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969aced",
   "metadata": {},
   "source": [
    "## Scoreboard\n",
    "\n",
    "After running one or more tasks, execute the cell below to summarize keyword checks and preview truncated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "if not TASK_LOG:\n",
    "    print('No tasks have been executed yet.')\n",
    "else:\n",
    "    summary = []\n",
    "    for entry in TASK_LOG:\n",
    "        summary.append({\n",
    "            'name': entry['name'],\n",
    "            'checks_passed': sum(1 for chk in entry['checks'] if chk['passed']),\n",
    "            'checks_total': len(entry['checks']),\n",
    "        })\n",
    "    pprint(summary)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
