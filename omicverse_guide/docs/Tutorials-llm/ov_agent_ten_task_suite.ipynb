{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd894374",
   "metadata": {},
   "source": [
    "# ov.Agent Ten-Task Regression Suite\n",
    "\n",
    "This notebook instantiates **ov.Agent** once and then reuses it across ten composite tasks that span end-to-end processing, multi-batch integration, trajectory inference, multiome alignment, tumor microenvironment analytics, and spatial modeling. Each task pairs a carefully worded ov.Agent prompt with lightweight validation hooks so you can quickly benchmark whether the agent still covers the relevant skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36ee7a",
   "metadata": {},
   "source": [
    "## Notebook structure\n",
    "\n",
    "1. Bootstrap ov.Agent with the same diagnostics used in `Tutorials-llm/t_ov_agent_pbmc3k.ipynb`.\n",
    "2. Load the [`ov_agent_tutorial_data_sources.md`](../../OvIntelligence/ov_agent_tutorial_data_sources.md) manifest so every task can remind you which local `.h5ad` files or remote links must be staged.\n",
    "3. Define ten task specs (prompt + datasets + keyword checks) and a helper `run_task` wrapper that:\n",
    "   - prints data reminders via `ensure_data(...)`\n",
    "   - calls `agent.chat(prompt)`\n",
    "   - records simple keyword-based health checks in `TASK_LOG`\n",
    "4. Optionally loop through all specs to stress-test ov.Agent end to end, then summarize pass/fail status in a scoreboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, omicverse as ov\n",
    "print(sys.executable)\n",
    "print('omicverse', getattr(ov, '__version__', 'unknown'), ov.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "import scanpy as sc\n",
    "import omicverse as ov\n",
    "\n",
    "print('OmicVerse version:', getattr(ov, '__version__', 'unknown'))\n",
    "print('Supported models:', ov.list_supported_models())\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '')\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '')\n",
    "\n",
    "if not (OPENAI_API_KEY or ANTHROPIC_API_KEY or GEMINI_API_KEY):\n",
    "    print('Warning: set OPENAI_API_KEY / ANTHROPIC_API_KEY / GEMINI_API_KEY before running live ov.Agent requests.')\n",
    "\n",
    "model_id = 'gpt-5'\n",
    "api_key = OPENAI_API_KEY or ANTHROPIC_API_KEY or GEMINI_API_KEY\n",
    "agent = ov.Agent(model=model_id, api_key=api_key)\n",
    "agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f14b8",
   "metadata": {},
   "source": [
    "## Data source manifest helper\n",
    "\n",
    "`ensure_data(...)` looks up tutorial references inside `OvIntelligence/ov_agent_tutorial_data_sources.md` so that each task can remind you which `.h5ad` or model files should be prepared ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a792875",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_PATH = Path('OvIntelligence/ov_agent_tutorial_data_sources.md')\n",
    "\n",
    "def _parse_data_source_table():\n",
    "    mapping = {}\n",
    "    if not DATA_SOURCE_PATH.exists():\n",
    "        return mapping\n",
    "    current_section = None\n",
    "    for raw_line in DATA_SOURCE_PATH.read_text().splitlines():\n",
    "        line = raw_line.strip()\n",
    "        if line.startswith('## '):\n",
    "            current_section = line[3:].strip()\n",
    "            continue\n",
    "        if not line.startswith('| `Tutorial'):\n",
    "            continue\n",
    "        parts = [p.strip() for p in line.strip('|').split('|')]\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        tutorial_ref = parts[0].strip('`')\n",
    "        mapping[tutorial_ref] = {\n",
    "            'files': parts[1],\n",
    "            'size': parts[2],\n",
    "            'hint': parts[3],\n",
    "            'section': current_section,\n",
    "        }\n",
    "    return mapping\n",
    "\n",
    "DATA_SOURCES = _parse_data_source_table()\n",
    "print(f'Loaded {len(DATA_SOURCES)} tutorial rows from {DATA_SOURCE_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_data(tutorial_refs):\n",
    "    \"\"\"Print local-file reminders for the given tutorial references.\"\"\"\n",
    "    refs = tutorial_refs\n",
    "    if isinstance(refs, str):\n",
    "        refs = [refs]\n",
    "    display(Markdown('**Data reminders**'))\n",
    "    for ref in refs:\n",
    "        info = DATA_SOURCES.get(ref)\n",
    "        if info:\n",
    "            display(Markdown(\n",
    "                f'- `{ref}` (section: {info.get(\"section\", \"n/a\")}):\n",
    "'\n",
    "                f'  - Files/models: {info.get(\"files\", \"see tutorial\")}\n",
    "'\n",
    "                f'  - Approx. size: {info.get(\"size\", \"n/a\")}\n",
    "'\n",
    "                f'  - Source hint: {info.get(\"hint\", \"see tutorial\")}'\n",
    "            ))\n",
    "        else:\n",
    "            display(Markdown(f'- `{ref}`: not found in manifest — consult the tutorial README.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857fe2a",
   "metadata": {},
   "source": [
    "## Task catalog\n",
    "Each entry specifies a real-world ov.Agent prompt, the tutorial references whose data are required, and lightweight keyword checks. The prompts deliberately cite ov.Agent's skill registry entries instead of notebook filenames so they can be executed directly inside the agent without leaking reference documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5502cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_SPECS = [\n",
    "    {\n",
    "        'name': 'PBMC 5k/8k FASTQ → QC → cluster-stability benchmarking',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_alignment_1k.ipynb',\n",
    "            'Tutorials-single/t_preprocess.ipynb',\n",
    "            'Tutorials-single/t_cluster.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"You are ov.Agent orchestrating an end-to-end PBMC 5k/8k workflow.\n",
    "\n",
    "Use the skill registry to load and cite:\n",
    "- `single-preprocessing` for QC/HVG/scaling guidance.\n",
    "- `single-clustering` for multi-head resolution sweeps.\n",
    "- `data-viz-plots` plus `single-downstream-analysis` for stability diagnostics.\n",
    "\n",
    "Requirements:\n",
    "1. Start from raw 10x FASTQs, run kb-python alignment to generate `adata.h5ad` counts (show CLI commands).\n",
    "2. Apply PBMC-grade QC thresholds, normalization, and HVG selection, documenting parameter choices.\n",
    "3. Run Leiden, Louvain, Gaussian mixture, and LDA clustering across several resolutions, computing UMAP drift metrics that quantify stability.\n",
    "4. Return ordered code blocks plus a markdown table summarizing head, resolution, drift (0–1), and the recommended resolution.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions kb-python alignment', 'keywords': ['kb-python', 'FASTQ']},\n",
    "            {'description': 'Reports UMAP drift or stability table', 'keywords': ['UMAP', 'drift']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Pancreas multi-study merge with SIMBA embeddings',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_single_batch.ipynb',\n",
    "            'Tutorials-single/t_simba.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Integrate the Baron, Segerstolpe, and Muraro pancreas scRNA-seq donors under strong batch effects.\n",
    "\n",
    "Use the registry to load:\n",
    "- `single-preprocessing` for donor-level normalization and covariate regression.\n",
    "- `single-multiomics` for SIMBA-style heterogeneous graph construction.\n",
    "- `single-clustering` and `data-viz-plots` for UMAP diagnostics.\n",
    "\n",
    "Workflow expectations:\n",
    "1. Highlight how to harmonize preprocessing parameters across cohorts before building the SIMBA graph.\n",
    "2. Provide the concrete SIMBA commands that add nodes/edges, train embeddings, and export 2D projections.\n",
    "3. Quantify integration with before/after UMAPs, kBET, and silhouette scores, commenting on endocrine vs. exocrine separation.\n",
    "4. Explain how to persist the learned embeddings for downstream classifiers.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'References SIMBA graph embedding', 'keywords': ['SIMBA', 'embedding']},\n",
    "            {'description': 'Includes kBET or silhouette metrics', 'keywords': ['kBET', 'silhouette']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Paul15 hematopoietic trajectories with MetaTiME diagnostics',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_traj.ipynb',\n",
    "            'Tutorials-single/t_metatime.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Reconstruct megakaryocyte vs. lymphoid trajectories on Paul15-like hematopoiesis data.\n",
    "\n",
    "Use the registry to pull:\n",
    "- `single-trajectory` for diffusion, PAGA, Palantir/VIA, and MetaTiME checkpoints.\n",
    "- `single-preprocessing` for QC and normalization.\n",
    "- `single-downstream-analysis` plus `data-viz-plots` for marker summaries.\n",
    "\n",
    "Deliverables:\n",
    "1. Describe preprocessing plus neighborhood graph construction before diffusion/PAGA.\n",
    "2. Run diffusion maps, Palantir/VIA, and identify root and terminal states with pseudotime ordering.\n",
    "3. Produce branch marker tables for at least two fates and explain MetaTiME cycle diagnostics that validate the ordering.\n",
    "4. Return code snippets, saved-figure descriptions, and a markdown list of pseudotime milestones.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions diffusion/Palantir', 'keywords': ['diffusion', 'Palantir']},\n",
    "            {'description': 'Cites MetaTiME diagnostics', 'keywords': ['MetaTiME', 'cycling']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'PBMC Multiome 10k GLUE + MOFA factor discovery',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_mofa_glue.ipynb',\n",
    "            'Tutorials-single/t_mofa.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Perform cross-modal alignment for PBMC Multiome 10k.\n",
    "\n",
    "Use skill registry lookups for:\n",
    "- `single-multiomics` (GLUE pairing + MOFA training).\n",
    "- `single-preprocessing` (modality-specific normalization).\n",
    "- `data-viz-plots` (factor visualization).\n",
    "\n",
    "Tasks:\n",
    "1. Pair RNA and ATAC embeddings with GLUE and report the path to the paired metadata.\n",
    "2. Train MOFA on matched matrices, labelling shared, RNA-only, and ATAC-only factors with variance explained tables.\n",
    "3. Highlight at least one IFN-response and one chromatin-accessibility-specific factor, with marker genes/peaks.\n",
    "4. Provide code snippets plus interpretation bullets for each factor category.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'GLUE pairing mentioned', 'keywords': ['GLUE', 'pair']},\n",
    "            {'description': 'MOFA factor summaries provided', 'keywords': ['MOFA', 'factor']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'PBMC 5k scATAC label transfer via GLUE embeddings',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_anno_trans.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Transfer PBMC RNA annotations onto PBMC 5k scATAC cells.\n",
    "\n",
    "Use skill registry entries:\n",
    "- `single-multiomics` for GLUE-derived embeddings and cross-modal graphs.\n",
    "- `single-annotation` for label transfer/validation patterns.\n",
    "\n",
    "Instructions:\n",
    "1. Load the GLUE embeddings (`data/analysis_lymph/rna-emb.h5ad` and `data/analysis_lymph/atac-emb.h5ad`).\n",
    "2. Build the cross-modal KNN graph, migrate labels with confidence, and surface per-cluster agreement statistics.\n",
    "3. Flag potential mismatches and explain how to visualize transferred labels on ATAC UMAPs.\n",
    "4. Return python commands plus a markdown table of cluster vs. confidence.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions cross-modal KNN transfer', 'keywords': ['KNN', 'transfer']},\n",
    "            {'description': 'Reports confidence per cluster', 'keywords': ['confidence', 'cluster']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Tumor microenvironment ligand–receptor diagnostics (CellPhoneDBViz)',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_cellphonedb.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Contrast ligand–receptor usage between exhausted T cells and M2 macrophages for treated vs. untreated tumors.\n",
    "\n",
    "Use registry calls for:\n",
    "- `single-cellphone-db` (interaction formatting, execution, visualization).\n",
    "- `single-downstream-analysis` and `data-viz-plots` (interpretation + figure export).\n",
    "\n",
    "Expectations:\n",
    "1. Show metadata formatting, CellPhoneDB execution commands, and result parsing.\n",
    "2. Highlight top ligand–receptor pairs per condition with effect sizes/p-values.\n",
    "3. Describe how to build heatmaps and chord diagrams (include filenames) via CellPhoneDBViz helpers.\n",
    "4. Provide interpretation guidance on shifts between conditions.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'CellPhoneDB workflow described', 'keywords': ['CellPhoneDB', 'ligand']},\n",
    "            {'description': 'Mentions visualization artifacts', 'keywords': ['heatmap', 'chord']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'MetaTiME-driven immune microenvironment annotation',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_metatime.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Annotate tumor-infiltrating immune cells with MetaTiME.\n",
    "\n",
    "Use skill registry lookups for:\n",
    "- `single-trajectory` (MetaTiME scoring + pseudotime context).\n",
    "- `single-preprocessing` (optional inferCNV-based malignant removal).\n",
    "- `single-downstream-analysis` (report formatting).\n",
    "\n",
    "Deliverables:\n",
    "1. Optionally filter malignant cells via infercnvpy outputs and recompute neighbors in SCVI space.\n",
    "2. Run MetaTiME scoring, rank meta-components per cluster, and interpret dominant immune states.\n",
    "3. Provide preprocessing + scoring code plus a markdown report mapping cluster → top meta-component with interpretation.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions MetaTiME scoring', 'keywords': ['MetaTiME', 'meta-component']},\n",
    "            {'description': 'References SCVI neighbors/inferCNV filtering', 'keywords': ['SCVI', 'inferCNV']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'CEFCON driver regulator discovery',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_cellfate.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Discover lineage-specific driver regulators with CEFCON on Nestorowa/Paul15 hematopoiesis.\n",
    "\n",
    "Use the registry to load:\n",
    "- `single-trajectory` (fate modeling context).\n",
    "- `single-downstream-analysis` (regulator reporting).\n",
    "\n",
    "Steps:\n",
    "1. Document preprocessing and prior network setup, including how to load the NicheNet graph.\n",
    "2. Run `ov.single.pyCEFCON`, exporting regulon tables for at least two branches (erythroid vs. granulocyte).\n",
    "3. Provide tuning advice (walk length, regularization) and show how to visualize regulator activity heatmaps.\n",
    "4. Summarize key regulators per branch in markdown.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'Mentions CEFCON run + prior network', 'keywords': ['CEFCON', 'NicheNet']},\n",
    "            {'description': 'Reports regulon or regulator tables', 'keywords': ['regulon', 'regulator']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Precision oncology prioritization (inferCNV + scDrug)',\n",
    "        'datasets': [\n",
    "            'Tutorials-single/t_scdrug.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Combine inferCNV-based malignant calling with scDrug predictions for precision oncology.\n",
    "\n",
    "Use registry lookups for:\n",
    "- `single-multiomics` (scDrug + modality handling).\n",
    "- `single-downstream-analysis` (drug ranking summaries).\n",
    "- `data-viz-plots` (CNV heatmap references).\n",
    "\n",
    "Workflow:\n",
    "1. Run infercnvpy to separate malignant vs. normal cells and reference the CNV heatmap artifact.\n",
    "2. Feed malignant clones into scDrug, compute predicted IC50 values, and rank at least five compounds per clone.\n",
    "3. Provide code for exporting the ranking table plus guidance on cross-referencing copy-number context when interpreting drug hits.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'inferCNV workflow described', 'keywords': ['inferCNV', 'CNV']},\n",
    "            {'description': 'scDrug IC50 ranking reported', 'keywords': ['scDrug', 'IC50']},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        'name': 'Spatial pseudo-time + alignment (SpaceFlow + STAligner)',\n",
    "        'datasets': [\n",
    "            'Tutorials-space/t_spaceflow.ipynb',\n",
    "            'Tutorials-space/t_staligner.ipynb',\n",
    "        ],\n",
    "        'prompt': \"\"\"Analyze Visium DLPFC slices with spatial pseudo-time and cross-slice alignment.\n",
    "\n",
    "Use the skill registry to load:\n",
    "- `single-to-spatial-mapping` and `spatial-tutorials` for Visium preprocessing, SpaceFlow, and STAligner steps.\n",
    "- `data-viz-plots` for reporting aligned layer maps.\n",
    "\n",
    "Expectations:\n",
    "1. Run SpaceFlow on slice 151676, computing embeddings, domains, and pseudo-spatiotemporal maps (pSM) from the `151676_filtered_feature_bc_matrix.h5` input.\n",
    "2. Feed at least two consecutive slices into STAligner with triplet-loss GAT alignment, highlighting how cortical layers align.\n",
    "3. Report output filenames for aligned embeddings and describe conserved layers across slices in markdown.\"\"\",\n",
    "        'checks': [\n",
    "            {'description': 'SpaceFlow pseudo-time mentioned', 'keywords': ['SpaceFlow', 'pSM']},\n",
    "            {'description': 'STAligner alignment described', 'keywords': ['STAligner', 'alignment']},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "print(f\"{len(TASK_SPECS)} task specs loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2c26e",
   "metadata": {},
   "source": [
    "## Task runner utilities\n",
    "\n",
    "`run_task(...)` displays context, ensures data availability reminders, calls ov.Agent, and stores keyword-check results inside `TASK_LOG` for later summarization. Adjust `RESPONSE_PARSER` if your deployment returns structured JSON instead of plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_LOG = []\n",
    "\n",
    "def evaluate_response_text(response_text, checks):\n",
    "    text = response_text or ''\n",
    "    lower = text.lower()\n",
    "    results = []\n",
    "    for check in checks:\n",
    "        keywords = [kw.lower() for kw in check.get('keywords', [])]\n",
    "        passed = all(kw in lower for kw in keywords)\n",
    "        results.append({\n",
    "            'description': check.get('description', ''),\n",
    "            'keywords': keywords,\n",
    "            'passed': passed,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_task(spec):\n",
    "    display(Markdown(f\"## Task: {spec['name']}\"))\n",
    "    ensure_data(spec.get('datasets', []))\n",
    "    prompt = spec['prompt']\n",
    "    response = agent.chat(prompt)\n",
    "    if isinstance(response, dict):\n",
    "        response_text = json.dumps(response, indent=2)\n",
    "    else:\n",
    "        response_text = str(response)\n",
    "    checks = evaluate_response_text(response_text, spec.get('checks', []))\n",
    "    TASK_LOG.append({\n",
    "        'name': spec['name'],\n",
    "        'timestamp': datetime.utcnow().isoformat() + 'Z',\n",
    "        'checks': checks,\n",
    "        'response_preview': response_text[:2000],\n",
    "    })\n",
    "    display(Markdown('**Response preview**'))\n",
    "    display(Markdown(response_text[:2000]))\n",
    "    display(Markdown('**Check results**'))\n",
    "    for chk in checks:\n",
    "        status = '✅' if chk['passed'] else '❌'\n",
    "        display(Markdown(f\"- {status} {chk['description']} (keywords: {', '.join(chk['keywords'])})\"))\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84a7a1",
   "metadata": {},
   "source": [
    "## Execute the full suite\n",
    "\n",
    "Set `RUN_ALL = True` to launch all ten prompts sequentially. You can also call `run_task(TASK_SPECS[i])` manually for spot checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e015908",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ALL = False\n",
    "\n",
    "if RUN_ALL:\n",
    "    for spec in TASK_SPECS:\n",
    "        run_task(spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93abbdf",
   "metadata": {},
   "source": [
    "### Task 1: PBMC 5k/8k FASTQ → QC → cluster-stability benchmarking\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999639f4",
   "metadata": {},
   "source": [
    "### Task 2: Pancreas multi-study merge with SIMBA embeddings\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc709b48",
   "metadata": {},
   "source": [
    "### Task 3: Paul15 hematopoietic trajectories with MetaTiME diagnostics\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffd421",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6a0ac",
   "metadata": {},
   "source": [
    "### Task 4: PBMC Multiome 10k GLUE + MOFA factor discovery\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d69f6",
   "metadata": {},
   "source": [
    "### Task 5: PBMC 5k scATAC label transfer via GLUE embeddings\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a76b18",
   "metadata": {},
   "source": [
    "### Task 6: Tumor microenvironment ligand–receptor diagnostics (CellPhoneDBViz)\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b07cda",
   "metadata": {},
   "source": [
    "### Task 7: MetaTiME-driven immune microenvironment annotation\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d838a",
   "metadata": {},
   "source": [
    "### Task 8: CEFCON driver regulator discovery\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d8873",
   "metadata": {},
   "source": [
    "### Task 9: Precision oncology prioritization (inferCNV + scDrug)\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce6b24",
   "metadata": {},
   "source": [
    "### Task 10: Spatial pseudo-time + alignment (SpaceFlow + STAligner)\n",
    "Run this cell to execute only this scenario. The helper below will print data reminders and log the ov.Agent response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6febfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task(TASK_SPECS[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969aced",
   "metadata": {},
   "source": [
    "## Scoreboard\n",
    "\n",
    "After running one or more tasks, execute the cell below to summarize keyword checks and preview truncated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "if not TASK_LOG:\n",
    "    print('No tasks have been executed yet.')\n",
    "else:\n",
    "    summary = []\n",
    "    for entry in TASK_LOG:\n",
    "        summary.append({\n",
    "            'name': entry['name'],\n",
    "            'checks_passed': sum(1 for chk in entry['checks'] if chk['passed']),\n",
    "            'checks_total': len(entry['checks']),\n",
    "        })\n",
    "    pprint(summary)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
